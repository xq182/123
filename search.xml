<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/blog/2023/09/06/17%20/"/>
      <url>/blog/2023/09/06/17%20/</url>
      
        <content type="html"><![CDATA[<p>面试官您好，我叫熊强，现在是南昌大学软件工程应届生。大一的时候，主要学习了Java框架栈，mysql，redis，mq，ssm,SpringCloud常用组件,看一些常用框架的源码spring,nacos,sential。大二开始学一些云原生相关的知识，docker,k8s，开始做一些项目，小到个人博客，微软云+docker，电商项目都做过，已经成功用k8s部署到甲骨文的三个云主机节点,安装KubeSphere来持续集成持续交付。大三上半年去美团公司实习，主要从事的是美团到家研发平台的后端开发工作，主要负责美团电商、交易、广告相关功能模块的研发及优化工作，我主要是用一些美团自研的组件来完成一些需求。下半年在快手实习，主要在电商技术部-交易中心负责售后相关模块的研发及优化工作，做了一个买家首页红点查询开发的需求，将db中的数据通过<strong>kbus</strong>同步到es，实现自定义锁和限流组件,对标pdd，在下单返现金，到门槛后可以提现活动中，提供<strong>逆向规则</strong>，敲定等比例退方案 ，降低业务资损风险，提升用户体验， 用户端逆向交易资金表达的重构，售后链路各环节实现了与正向交易钱款、营销资产信息拉齐，新增展示了退营销资产信息，清晰透传各明细项分摊结果，并对后续各类营销玩法升级打下基础，提升迭代效率及用户体验， 减少用户针对资金的疑惑和cpo</p><p>赠送用户91块钱初始面额，累计100块钱可以提现，订单a实付100块钱，获得3块钱奖励金额，订单b实付100块钱，获得3块钱奖励金额，订单c实付100块钱，获得3块钱奖励金额，用户对订单a发起退款，追回金额=红包总金额×<em>（总门槛-剩余累计金额）/总门槛-上次=100</em>×20/30-100*×10/30，判断钱包余额是否足够，</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SELECT count(1) </span><br><span class="line">FROM kwaishop_refund </span><br><span class="line">WHERE buyer_id = #&#123;buyerId&#125; </span><br><span class="line">AND status IN (60, 70) </span><br><span class="line">AND assess_status = 0 </span><br><span class="line">AND end_time &gt;= #&#123;now - 1month&#125; </span><br><span class="line">AND valid_status = 0;</span><br></pre></td></tr></table></figure><p><img src="C:\Users\熊强\Pictures\学习资料\drawio(5).svg" alt="drawio(5)" style="zoom: 50%;" /></p><p>由于平台接入的数据达万级，消息队列积压严重，为提高消费端 ES 的写入，中间不单纯是一些写入，做各种各样的处理，插入到第三方表，为在售商品、标品提供文字、图片、视频违规信息的拦截，整体流程耗时非常严重，使用方不能及时搜索到商品的信息，第一期的话是全部改成批量操作，充分利用系统资源，发现这些指标还是上不去，像一些非核心的逻辑，要求不是那么实时，那我就开一个异步线程来异步化，迭代到最后面，攒批多线程插入，就先拉一批数据到全局队列中去，再开一个线程池，启动线程池，对数据进行分片后多线程批次插入，ES 提供了 Bulk API 支持批量操作，当我们有大量的写任务时，可以使用 Bulk 来进行批量写入。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">this.bufferTrigger = BufferTrigger.&lt;BuyerRefundSyncESParam&gt; </span><br><span class="line">*batchBlocking*().setConsumerEx(orderRefundList -&gt; threadPoolExecutor.execute(() -&gt; batchSyncES(orderRefundList))).batchSize(*200*).linger(*1000*, TimeUnit.*MILLISECONDS*).build();</span><br></pre></td></tr></table></figure><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p><img src="https://img.bosszhipin.com/beijin/upload/chatphoto/20230624/e14831a7cd1b6d13f59ac991338a8accb67f7c1e5820f0dcd2852831d7d44eecfe301e46efff4398.png" alt="img" style="zoom: 50%;" /></p><p><img src="https://img.bosszhipin.com/beijin/upload/chatphoto/20230624/e14831a7cd1b6d13ced5f04f9dd20fb767eae33759e8e383481eb61bcf77e7d879ce7d34578b8543.jpg" alt="img" style="zoom: 33%;" /></p><p><img src="https://img.bosszhipin.com/beijin/upload/chatphoto/20230624/e14831a7cd1b6d134a555e0915207c12e295352f9edaae49481eb61bcf77e7d879ce7d34578b8543.jpg" alt="img" style="zoom:33%;" /></p><p>针对接口的优化，当时也是采用了很多的手段，从代码层面，像一些三级菜单查询，我一开始使用了双重for循环，多此io数据库，时间复杂度很高，代码质量很差，后来我把最里层的for循环先在外面先查出来，减少数据库的io次数。从各个服务获取数据一开始都是同步调用，这样就被阻塞执行了，接口耗时长、性能差，接口响应时长，后来引入了CompletableFuture ，可以将多个没有先后关系的异步任务进行并发执行和可组合：可以将多个依赖操作通过不同的方式进行编排，例如CompletableFuture提供thenCompose、thenCombine等各种then开头的方法，这些方法就是对“可组合”特性的支持。从数据库层面，我会加合适的索引，并通过EXPLAIN命令分析他的执行计划，主要是三个字段，</p><p>type</p><p><strong>system</strong>：如果表使用的引擎对于表行数统计是精确的（如：MyISAM），且表中只有一行记录的情况下，访问方法是 system ，是 const 的一种特例。</p><p><strong>const</strong>：表中最多只有一行匹配的记录，一次查询就可以找到，常用于使用主键或唯一索引的所有字段作为查询条件。</p><p><strong>eq_ref</strong>：当连表查询时，前一张表的行在当前这张表中只有一行与之对应。是除了 system 与 const 之外最好的 join 方式，常用于使用主键或唯一索引的所有字段作为连表条件。</p><p><strong>ref</strong>：使用普通索引作为查询条件，查询结果可能找到多个符合条件的行。</p><p><strong>index_merge</strong>：当查询条件使用了多个索引时，表示开启了 Index Merge 优化，此时执行计划中的 key 列列出了使用到的索引。</p><p><strong>range</strong>：对索引列进行范围查询，执行计划中的 key 列表示哪个索引被使用了。</p><p><strong>index</strong>：查询遍历了整棵索引树，与 ALL 类似，只不过扫描的是索引，而索引一般在内存中，速度更快。</p><p><strong>ALL</strong>：全表扫描。</p><hr><p>Extra</p><p><strong>Using filesort</strong>：在排序时使用了外部的索引排序，没有用到表内索引进行排序。</p><p><strong>Using temporary</strong>：MySQL 需要创建临时表来存储查询的结果，常见于 ORDER BY 和 GROUP BY。</p><p><strong>Using index</strong>：表明查询使用了覆盖索引，不用回表，查询效率非常高。</p><p><strong>Using index condition</strong>：表示查询优化器选择使用了索引条件下推这个特性。</p><p><strong>Using where</strong>：表明查询使用了 WHERE 子句进行条件过滤。一般在没有使用到索引的时候会出现。</p><p><strong>Using join buffer (Block Nested Loop)</strong>：连表查询的方式，表示当被驱动表的没有使用索引的时候，MySQL 会先将驱动表读出来放到 join buffer 中，再遍历被驱动表与驱动表进行查询。</p><hr><h2 id="广告"><a href="#广告" class="headerlink" title="广告"></a>广告</h2><p>每一个广告都有一个租户ID和广告ID 标志着属于哪个企业投放的广告 当前端访问到广告的时候会像后端发送请求 携带ID等参数 后端会进行记录 以前端传递的参数区分是用户点击还是仅是刷到了消息，由于广告访问较为频繁使用redis作为数据源 定时任务持久化到数据库，确实定时任务是有延迟 但数据频繁改动直接操作数据库压力很大 线上计费规则直接使用redis统计 redis做持久化机制 定时任务只是保持最终一致性，限时读取redis数据持久化到数据库 主从分离 读取数据使用专门的读取redis 同时key和时间戳相关联不至于一次持久化很多数据造成阻塞,统计广告的点击量是为运营赋能的重要手段之一，可以帮助运营人员了解广告的点击情况，从而优化广告投放策略，提高广告的转化率和效果，HINCRBY ad:tenant_id:ad_id impression_count 1<br><img src="https://yqfile.alicdn.com/0e1f981d55a742a6aaf750513a99416f415ccadd.png" alt="_1"><br>通过上图可以看到点击数据首先存储到Redis Stream，然后通过StructuredStreaming消费数据、处理聚合数据，再把处理的结果入库到Redis，最后通过Spark Sql查询Redis进行统计分析。下面分别看下每个步骤：</p><h4 id="数据提取："><a href="#数据提取：" class="headerlink" title="数据提取："></a>数据提取：</h4><p>Redis Stream是Redis内置的数据结构，具备每秒百万级别的读写能力，另外存储的数据可以根据时间自动排序。Spark-Redis连接器支持使用Redis Stream作为数据源，非常适用这个场景，把Redis Stream数据对接到Spark 引擎。</p><h4 id="数据处理："><a href="#数据处理：" class="headerlink" title="数据处理："></a>数据处理：</h4><p>Spark的StructuredStreaming 非常适合此场景的数据处理部分，Spark-Redis连接器可以获取Redis Stream的数据转换成Spark的DataFrames。在StructuredStreaming处理流数据的过程中，可以对微批次数据或者整体数据进行查询。数据的处理结果可以通过自定义的“writer”输出到不同的目的地，本场景中我们直接把数据输出到Redis的Hash数据结构。</p><h4 id="数据查询："><a href="#数据查询：" class="headerlink" title="数据查询："></a>数据查询：</h4><p>Spark-Redis连接器可以把Redis的数据结构映射成Spark的DataFrames，然后我们把DataFrames创建成一个临时表，表的字段映射Redis的Hash数据结构。借助Redis的亚毫米级的延迟，使用Spark-SQL进行实时的数据查询。</p><p><img src="C:\Users\熊强\Pictures\学习资料\drawio(6).svg" alt="drawio(6)" style="zoom: 200%;" /></p><h2 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h2><p> 是一套帮助DevOps落地的通用持续交付平台。您可以通过Pipeline定制、固化产品交付过程中的各个环节。基于代码变更，Pipeline自动完成构建、测试、部署等一系列行为，减少交付流程中的人工操作成本和人为因素造成的问题。基础组件主要包括编译构建、单测、代码扫描、集成环境部署、分支合并、回归测试、Quake压测、Plus部署</p>]]></content>
      
      
      <categories>
          
          <category> mafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>oom线上问题排查</title>
      <link href="/blog/2023/08/26/29/"/>
      <url>/blog/2023/08/26/29/</url>
      
        <content type="html"><![CDATA[<h2 id="定时任务背景"><a href="#定时任务背景" class="headerlink" title="定时任务背景"></a><strong>定时任务背景</strong></h2><p>团队负责的一个后端服务某天环境出现无法启动的现象，本文通过此次问题排查，引出一些开发规范问题。</p><h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a><strong>现象</strong></h2><ul><li>测试环境部署后端服务一直无法启动；但是main.log没有任何异常信息</li><li>怀疑可能是启动时内存溢出。查看日志目录发现，多了很多hprof文件，起初怀疑可能是Metaspace溢出问题</li><li>但是这个项目的类很少，按理说不至于Metaspace溢出，于是查看stdout.log日志文件发现：<em>java.lang.OutOfMemoryError: Java heap space…</em>  竟然是堆内存溢出</li><li>但是以我对此服务的了解，更不应该出现启动时堆内存溢出的现象</li><li><p>开始分析hprof内存文件</p></li><li><p>先看下<strong>概况</strong></p></li></ul><p>com.mysql.jdbc.JDBC42ResultSet竟然占了<strong>2.08G</strong>，main线程也占了<strong>2.63G</strong></p><p>JDBC42ResultSet一定是某个sql查了一堆数据返回的结果</p><ul><li><p>再去<strong>支配树</strong>里找一下线索：先层层打开内存占用最大的主线程，找找线索，看看内存里都是哪些业务类的实例：里面竟然有7138519个LinkedCaseInsensitiveMap，但是这个不是我们项目里定义的业务实例，这是spring的JDBCTemplate用来放查询结果的，依然定位不了问题，怀疑有某个逻辑SELECT了某张表中所有数据</p><p>，找到sql</p></li><li><p>全局搜索sql，发现是项目中的一个Scheduled定时任务调用了上图的查询sql。好家伙，原来这个后端项目里有这么多@Scheduled定时任务！</p><p><strong>为什么会项目启动时执行？</strong></p><p>因为上图左侧scheduler包下的所有定时任务都是用@Scheduled注解方式开发，并用了fixedRate参数配置定时触发（fixedRate作用：任务运行后隔多久再次触发）。而第一次触发时间就是项目刚启动完时候。</p><p>这些定时任务都在后端服务里执行。</p><p><strong>这会导致以下问题：</strong></p><ul><li><p>如果有一个任务会出现OOM，那么此项目启动后将会直接OOM，然后重启后再次OOM（就是这次的现象）</p></li><li><p>即使各个任务都不会出现OOM，那么由于代码中有多个Scheduled，可能同时执行时内存膨胀导致OOM</p></li><li><p>某个任务如果出现一些其他不可预料的问题，那么将直接影响到后端服务的稳定性</p></li><li><p>后端服务多实例导致定时任务重复执行</p></li><li><p>定时任务执行时不断刷日志，影响后端服务线上问题排查</p><h2 id="规范"><a href="#规范" class="headerlink" title="规范"></a>规范</h2></li></ul></li><li><p>批量查询处理数据时，如果后续数据量可能膨胀过多，应使用分页查询处理，防止OOM</p></li><li>避免在后端服务里使用@Scheduled注解开发定时任务，应按照公司任务调度平台的API开发接入并单独部署</li></ul><h2 id="转码服务背景"><a href="#转码服务背景" class="headerlink" title="转码服务背景"></a>转码服务背景</h2><p> 有业务方反馈图片转码服务大量失败, 持续10分钟左右, 之后就恢复, 失败返回的错误中有oom异常. 收到反馈第一时间查看了机器的日志, 发现日志中并没有异常.最后从内存监控和重启日志的时间点上来看服务发生了重启.</p><p>在没有找到OOM发生时的现场的情况下, 可以通过查看运行时的内存信息来定位内存问题, 因为OOM的发生, 是由于java对象大量积压在老生代无法回收导致的, 通常这个积压的过程会持续相对较长的一段时间, 才会发生OOM. 大部分情况下, 不会出现之前一直是正常的, 在短时间内积压大量无法回收的java对象的情况.所以,可以通过下面的三个命令来排查问题.</p><p>jmap - heap <pid>显示Java堆详细信息， Heap Configuration展示的是jvm的设置,Heap Usage是堆内存的使用情况, 其中G1 heap是总体情况, G1 Young Generation是年轻代内存情况, G1 Old Generation是老年代内存情况.</p><p>jmap -histo <pid></p><p>  查看指定pid的java进程中, java对象的内存占用量(从大到小排序), 可以持续的观察, 关注那些长时间无法回收的java对象, 或者数量明显异常偏多的java对象.</p><p> jmap -histo:live <pid> 来手动触发一次Full GC</p><p>通过上面的排查我们推测jvm可能不是自己OOM挂掉了, 于是, 我们使用dmesg -T来参看是否有java进程被kill的记录,通过上面的信息,发现JVM确实是被kill掉了, 时间点也与最上面图1系统监控中重启的时间点相吻合.而JVM被kill掉的原因是FFmpeg在申请内存的时候, 系统发现内存不足, 申请不到内存了, 于是, 通过计算的权重kill掉了占用最多内存的JVM.</p><p>其中重要的参数有2个:</p><p>-XX:InitialRAMPercentage=60 // JVM初始堆内存分配为容器内存的60%</p><p>-XX:MaxRAMPercentage=60, // JVM最大堆内存分配为容器内存的60%</p><p>而容器内存是16G, JVM启动就申请了8192M, 然后其他配置MetaSpace申请了512M, 堆外内存申请了2G,然后容器本身还需要占用一部分内存, 这样最后剩下的内存就不多了, 转码服务需要执行大量的FFmpeg命令,这些都是独立启动一个进程来执行的,FFmpeg的执行也需要大量的内存, 这样就导致了, FFmpeg在执行的时候申请不到内存,然后, 系统就kill掉了JVM的进程.</p><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>在我们的例子中主要是JVM占用了太多内存导致的, 解决的思路有两个, 第一种: 直接调整MaxRAMPercentage减少最大内存, 简单直接. 第二种: 由于我们的内存回收很健康, 所以可以调整-XX:InitialRAMPercentage为40, 这样就不会启动就申请60%, 而是申请40%, 在运行过程中, 由于内存在GC的时候可以正常回收, 所以不会有占满60%的情况</p>]]></content>
      
      
      <categories>
          
          <category> redis集群key </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis集群key </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis集群key</title>
      <link href="/blog/2023/08/25/28/"/>
      <url>/blog/2023/08/25/28/</url>
      
        <content type="html"><![CDATA[<h1 id="发现问题"><a href="#发现问题" class="headerlink" title="发现问题"></a>发现问题</h1><p>7月29号， 晚上23:30我们收到kcc报警，我们有个redis集群liveStreamStats内存使用率达到了90%。<br><img src="C:\Users\熊强\Pictures\学习资料\e15b2f6540541d19a980b5d1c949ad6c.png" alt="file" style="zoom:33%;" /><br><img src="https://static.yximgs.com/udata/pkg/EE-KSTACK/46b68a66ffdbc7150dd7f0938609c112.png" alt="file"></p><p>发现有两个redis实例redis使用率到了90%，但是其他的实例内存并没有这么高。</p><h1 id="问题止损"><a href="#问题止损" class="headerlink" title="问题止损"></a>问题止损</h1><p>    因为当时7月29号成龙大哥在开播，并且开播时间是19:50，和监控上内存上涨的时间点吻合，我们怀疑和成龙大哥开播在线人数比较多导致的。当时紧急联系kcc同学垂直扩容了这两台实例。</p><h1 id="问题初步定位"><a href="#问题初步定位" class="headerlink" title="问题初步定位"></a>问题初步定位</h1><p>    当时kcc同学通过解析rdb数据发现以wd_11285866346:（11285866346是成龙大哥的liveStreamId)为前缀的key在这两台实例占的内存最多，对应hash key大概有3w个filed。结合liveStreamStats集群上游服务和成龙大哥在线观众行为，我们怀疑是通过处理观众心跳消息记录观看时长的consumer有数据倾斜或者大key问题，导致liveStreamStats集群中两台实例内存使用率到达90%，通过前缀查看定位到具体代码：<br>通过代码和redis key确认，确实是这个逻辑有问题。</p><h2 id="是否是存在大key问题"><a href="#是否是存在大key问题" class="headerlink" title="是否是存在大key问题"></a><strong>是否是存在大key问题</strong></h2><p>   可以通过代码看出来，我们记录直播间观众观看时长用的是redis的hash结构，我们在设计这块的时候考虑到，如果一个直播在线人数很大，用一个hash储存会有大key的问题，所以我们在代码中<strong>根据userId进行单一大hash结构</strong>的拆分。<br><img src="https://static.yximgs.com/udata/pkg/EE-KSTACK/e33d6283c2ffecebdfb71e7a94b215fd.png" alt="file"><br>wd_liveid:userid后三位  userid value   </p><p>从代码上看，我们通过userId分出来了1000个hash，应该不会出现大key的问题，另外结合成龙大哥间內观看人数大概2600w人，1000个hash结构，每个hash有3w左右个filed，每个key数据还是比较均匀的。所以应该不是这个，<strong>pass</strong>。</p><h2 id="是否是有数据倾斜问题"><a href="#是否是有数据倾斜问题" class="headerlink" title="是否是有数据倾斜问题"></a><strong>是否是有数据倾斜问题</strong></h2><p>   从上面代码来看，业务层通过userId做了hash的拆分，并且key的拼接方式是wd_{liveStreamId}:{0-999}的，按理说kcc-proxy会将每个key均匀的分到每台集群上，不太可能会有数据倾斜呀。我们同时去看了一下之前做的新uv pv服务使用的也是用的这个hash结构，同时就是用的一模一样的拆分逻辑，但是那个集群liveUvPvStatistic没有数据倾斜，但是liveUvPvStatistic集群的实例数是320个节点，liveStreamStats集群是174个节点，我们怀疑proxy的分片是否均匀可能与key的形式和实例个数有关。</p><h1 id="问题复现"><a href="#问题复现" class="headerlink" title="问题复现"></a>问题复现</h1><p>   因为怀疑可能与proxy的分片算法有关，在kcc同学的帮助下，我们得知咱们快手用的redis集群proxy用的是Twitter的twemproxy代理系统，同时咱们快手这边用的key的hash算法是 <strong>fnv1a_64</strong>(twmproxy默认算法），数据分配方式（distribution）用的是根据<strong>key做hash值取模</strong>（modula）。同时kcc同学提供了一下fnv1a_64 java版的算法代码，我们基于这个代码写了个测试用例来模拟线上hash key的分片逻辑。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LiveFnv1a64Test</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">FNV_64_INIT</span> <span class="operator">=</span> <span class="number">0xcbf29ce484222325L</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">FNV_64_PRIME</span> <span class="operator">=</span> <span class="number">0x100000001b3L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">long</span> <span class="title function_">hash</span><span class="params">(<span class="keyword">final</span> String k)</span> &#123;</span><br><span class="line">        <span class="type">long</span> <span class="variable">rv</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">len</span> <span class="operator">=</span> k.length();</span><br><span class="line">        rv = FNV_64_INIT;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; len; i++) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">c</span> <span class="operator">=</span> k.charAt(i);</span><br><span class="line">            rv ^=  c;</span><br><span class="line">            rv *= FNV_64_PRIME;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> rv &amp; <span class="number">0xffffffffL</span>; <span class="comment">/* Truncate to 32-bits */</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">hashWatchCountKey</span><span class="params">(<span class="type">int</span> mcCount)</span> &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">keyPrefix</span> <span class="operator">=</span> <span class="string">&quot;wd_11285866346:&quot;</span>;</span><br><span class="line">        Map&lt;Integer, Integer&gt; hashCount = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">999</span>; i++) &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> keyPrefix + i;</span><br><span class="line">            <span class="type">int</span> <span class="variable">hashValue</span> <span class="operator">=</span> (<span class="type">int</span>) (hash(key) % mcCount);</span><br><span class="line">            hashCount.compute(hashValue, (k, v) -&gt; &#123;</span><br><span class="line">                <span class="keyword">if</span> (v == <span class="literal">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="keyword">return</span> v + <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;mcCount: &quot;</span>+mcCount + <span class="string">&quot; modClientCount: &quot;</span> + hashCount.keySet().size() + <span class="string">&quot; modClientmap:&quot;</span>+hashCount);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">hashKey</span><span class="params">()</span>&#123;</span><br><span class="line">        hashWatchCountKey(<span class="number">174</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>   其中for循环中的0-999模拟genShardedKey(keyPrefix, shardKey % shardSize) shardSize=1000，mcCount模拟redis集群有174台实例。输出的结果如下：<br><img src="https://static.yximgs.com/udata/pkg/EE-KSTACK/9bedf91a2a6f28f3e3c2a4bcb8c970f0.png" alt="file"><br>其中modClientCount是指路由到的redis实例个数，modClientmap的key代表<strong>路由的对应的redis实例id</strong>，value表示<strong>对应实例分配redis key个数</strong>，我们通过结果发现1000个redis key并没有均匀的分配到174个实例上，只分配了6个，并且其中两台分配了400多个key，和线上的现象一样，有两个实例内存快爆了。</p><h1 id="问题推理"><a href="#问题推理" class="headerlink" title="问题推理"></a>问题推理</h1><p>   现在可以确定就是数据倾斜问题，那么会是key的问题还是机器实例的问题？<br>为什么这样想问题呢，因为这个redis key分片到哪个实例，可以看做是一个函数<br>   输入：拼装的key &amp; redis实例数<br>   function：是fnv1a_64算法<br>   输出：对应key到实例映射。<br>所以我们先看看不同的输入会有什么结果</p><h2 id="2-redis-key的拼装"><a href="#2-redis-key的拼装" class="headerlink" title="2.redis key的拼装"></a>2.redis key的拼装</h2><p>   我们可以发现这个key中的变量是0-999的slot，现在slot的位置在最后，如果在redis实例数不变，我们把slot值弄到中间或者最前面呢会是什么样？<br>我们分别将key的拼装方式变成：</p><ul><li>前缀拼接：{0-999}:wd_11285866346</li><li>中缀拼接：wd_{0-999}:11285866346</li><li>后缀拼接：wd_11285866346:{0-999}<br><img src="https://static.yximgs.com/udata/pkg/EE-KSTACK/f87edc857a4125a492863228a85fd8f7.png" alt="file"></li></ul><p>what!!只有后缀拼接分片特别不均衡，为什么，一会咱们可以通过公式推理一下</p><h1 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h1><p>首先这个问题可以抽象成一下步骤：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 首先一个hash函数对key数组做hash，得出一个int型的hash数组，&#123;h&#125; = hash(&#123;key&#125;)</span><br><span class="line">2. 然后这个hash数组&#123;h&#125;通过求模运算，将对应hash值映射到 m 个槽上，从而得到key需要映射到的对应实例，</span><br><span class="line">h(&#123;h&#125;) = &#123;h&#125; mod m</span><br></pre></td></tr></table></figure><p>输入：{key}是key字符串数组，m是redis实例个数。<br>函数：hash就是fnv1a_64算法<br>输出：h({h}) 的结果就是映射map，其中{h}就是hash之后的int数组（这个很重要后面推理要用）。</p><p>怎么能让key可以更均匀的散列到不同的槽位中，不发生数据倾斜呢？有三种定义：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 如果&#123;h&#125;数列间隔的分布越均匀，那么不管模数为几都会均匀分布，冲突的比较小。</span><br><span class="line">2. 如果&#123;h&#125;数列间隔和模数有公因子，则容易发生冲突，且公因子越多，冲突的可能性越多。公因子越少，冲突的可能性越少。</span><br><span class="line">3. 如果模数是素数，会比较均匀分布，冲突的比较小。（因为素数只有两个因数，一个1一个本身）</span><br></pre></td></tr></table></figure><p><strong>第一个方法</strong>很好证明，如果hash数组里面的间隔越分散不管模几都均匀，因为分母的数字均匀呀，不管除几求余，后面的余数近似随机。</p><p><strong>第二个方法</strong>可以简单解释一下，比如一个h({m}) = {m} % n，{m}是有序数组并且间隔一样记作g，间隔数g因子有a b c e，其中n的因子有 a b f g。那么:<br>   m1求模应该是 h(m1) = m1 % n<br>   m2求模应该是 h(m2) = m2 % n = (m1 + g) %n<br>   m3求模应该是 h(m3) = m3 % n = (m1 + 2g) %n<br>   m…求模应该是 h(m..) = m.. % n = (m1 + (..-1)g) %n<br>g和n有公因子，那么m1%n模出来的是一样的，k*g%n应该模出来的数是一样的，通过模运算的结合律，它们是线性结合，所以总起来模出来的数应该是一样的，从而数列间隔和模数有公因子，则容易发生冲突，且公因子越多。<br>这个推理不够完备，因为模数的结合律不是简单相加，但是是近似线性，具体可以问一下ChatGPT 4通过概率论和数学推理可以完整的推导出来的，举例论证可以看这篇<a href="https://blog.csdn.net/afei__/article/details/83010897">文章</a></p><p><strong>第三个方法</strong>在大学里学数据结构hash的时候老师讲过了，具体的数学推理可以看一下这篇<a href="https://flat2010.github.io/2018/04/19/模运算中为何要用素数作为模">文章</a></p><h2 id="1-redis将int-slot放到前缀或者中缀，散列值分布均匀"><a href="#1-redis将int-slot放到前缀或者中缀，散列值分布均匀" class="headerlink" title="1.redis将int slot放到前缀或者中缀，散列值分布均匀"></a>1.redis将int slot放到前缀或者中缀，散列值分布均匀</h2><p>为什么偏斜呢？</p><p>可以看的出来fnv1a_64是种线性算法，它会将输入的数据逐个字符进行处理。<br>   当slot放到后缀的时候，前缀的部分”wd_11285866346:”对散列值的影响在<strong>每次key迭代</strong>中都是相同的，而只有在最后slot{i}变量相乘时散列值才会不一样，因此slot{i}并不能充分的影响到这个64位的散列值，这就导致了散列值的偏移。<br>   当slot放到前缀或者中间的时候，每次迭代的输入值都是不同的，所以槽变量slot{i}的改变几乎可以在整个64位散列值都有影响，从而使得散列值分布更均匀。</p><h2 id="2-redis实例数如果是素数和2的n次方，散列值分布均匀"><a href="#2-redis实例数如果是素数和2的n次方，散列值分布均匀" class="headerlink" title="2.redis实例数如果是素数和2的n次方，散列值分布均匀"></a>2.redis实例数如果是素数和2的n次方，散列值分布均匀</h2><h3 id="在slot为后缀的时候，为什么模数是174偏移这么严重"><a href="#在slot为后缀的时候，为什么模数是174偏移这么严重" class="headerlink" title="在slot为后缀的时候，为什么模数是174偏移这么严重"></a>在slot为后缀的时候，为什么模数是174偏移这么严重</h3><p>先解释一下实例数是174的时候，为什么偏移这么严重。<br>根据定义二，hash数列间隔和模数有公因子，则容易发生冲突，且公因子越多，冲突的可能性越多。那我们现在先看一下hash数列间隔是怎么分布的。先写一个测试用例看一下hash数列间隔分布如下：</p><p>其中gapList是hash数列间隔的List，gapGroupMap是hash数列间隔分布情况，咱们可以debug一下：<br>可以发现一共999个间隔，其中间隔为435的就占有825个。为什么间隔数有这么多435，算法中*435。<br>   435的因数为</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">435</span> = <span class="number">3</span> *<span class="number">5</span> * <span class="number">29</span></span><br></pre></td></tr></table></figure><p>   174的因数为</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">174</span> = <span class="number">2</span> * <span class="number">3</span> * <span class="number">29</span></span><br></pre></td></tr></table></figure><p>hash数列间隔435和模数174个公因子有两个，所以分片出来的key有数据倾斜。</p><h3 id="在slot任意，为什么模数是素数比较均匀"><a href="#在slot任意，为什么模数是素数比较均匀" class="headerlink" title="在slot任意，为什么模数是素数比较均匀"></a>在slot任意，为什么模数是素数比较均匀</h3><p>这个前面解释过了，不在这里赘述了，具体的数学推理可以看一下这篇<a href="https://blog.csdn.net/afei__/article/details/83010897">文章</a></p><h3 id="在slot任意，为什么模数是2的指数幂比较均匀"><a href="#在slot任意，为什么模数是2的指数幂比较均匀" class="headerlink" title="在slot任意，为什么模数是2的指数幂比较均匀"></a>在slot任意，为什么模数是2的指数幂比较均匀</h3><p>在理解174为啥偏移严重的基础上，我们可以很简单的知道&amp;<br>    435的因数为</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">435</span> = <span class="number">3</span> *<span class="number">5</span> * <span class="number">29</span></span><br></pre></td></tr></table></figure><p>2的指数幂的因数都是2的倍数，所以他们没有公因数，从而比较均匀，没有什么偏移。</p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>如果业务中用的key拼接策略是将slot拼接到后缀，并且redis实例数如果不是素数或者2的指数幂，redis集群就<strong>有可能</strong>出现严重的数据倾斜。所以解决方案如下：</p><h2 id="1-将redis-key的拼接规则改成slot数字作为前缀或者中缀"><a href="#1-将redis-key的拼接规则改成slot数字作为前缀或者中缀" class="headerlink" title="1.将redis key的拼接规则改成slot数字作为前缀或者中缀"></a>1.将redis key的拼接规则改成slot数字作为前缀或者中缀</h2><h2 id="2-在申请redis集群时，可以将集群个数设置2的n次方"><a href="#2-在申请redis集群时，可以将集群个数设置2的n次方" class="headerlink" title="2.在申请redis集群时，可以将集群个数设置2的n次方"></a>2.在申请redis集群时，可以将集群个数设置2的n次方</h2><p>虽然实例数为素数，数据分布比较均匀，但是素数基本是奇数结尾，kcc在分配集群机器时不太好分配，所以最好不要用素数作为实例数。</p><h2 id="3-proxy换成其他hash算法"><a href="#3-proxy换成其他hash算法" class="headerlink" title="3.proxy换成其他hash算法"></a>3.proxy换成其他hash算法</h2><ul><li><p>murmur</p></li><li><p>fnv1_64hash</p><p>当前线上用的是fnv1a_64，但是因为当前快手redis相关平台都是基于这个算法建设的，改动成本比较大。</p><h1 id="最优的解决方案"><a href="#最优的解决方案" class="headerlink" title="最优的解决方案"></a>最优的解决方案</h1><p>   综合成本和安全性，将redis key的拼接规则改成slot数字作为前缀或者中缀，尽量让变量多参与计算是最优的。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> redis集群key </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis集群key </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spring容器的创建过程</title>
      <link href="/blog/2023/08/14/9/"/>
      <url>/blog/2023/08/14/9/</url>
      
        <content type="html"><![CDATA[<p>@SpringBootApplication<br>等同于<br>@SpringBootConfiguration<br>@EnableAutoConfiguration   @Import(AutoConfigurationImportSelector.class)<br>@ComponentScan(“com.atguigu.boot”)  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public ApplicationContext(annotatedClasses)</span><br><span class="line">&#123;</span><br><span class="line">this();</span><br><span class="line">//注册配置类， 因为配置需要解析，一般不需自己扫描</span><br><span class="line">register(annotatedClasses) ;</span><br><span class="line">refresh();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Spring容器的refresh()【创建刷新】;</p><p>1、prepareRefresh()刷新前的预处理;</p><p>  1）、initPropertySources()初始化一些属性设置;子类自定义个性化的属性设置方法；</p><p>  2）、getEnvironment().validateRequiredProperties();检验属性的合法等</p><p>  3）、earlyApplicationEvents= new LinkedHashSet<ApplicationEvent>();保存容器中的一些早期的事件；</p><p>2、obtainFreshBeanFactory();获取BeanFactory；</p><p>  1）、refreshBeanFactory();刷新【创建】BeanFactory；</p><p>​      创建了一个this.beanFactory = new DefaultListableBeanFactory();</p><p>​      设置id；</p><p>  2）、getBeanFactory();返回刚才GenericApplicationContext创建的BeanFactory对象；</p><p>  3）、将创建的BeanFactory【DefaultListableBeanFactory】返回；</p><p>3、prepareBeanFactory(beanFactory);BeanFactory的预准备工作（BeanFactory进行一些设置）；</p><p>  1）、设置BeanFactory的类加载器、支持表达式解析器…</p><p>  2）、添加部分BeanPostProcessor【ApplicationContextAwareProcessor】</p><p>  3）、设置忽略的自动装配的接口EnvironmentAware、EmbeddedValueResolverAware、xxx；</p><p>  4）、注册可以解析的自动装配；我们能直接在任何组件中自动注入：</p><p>​      BeanFactory、ResourceLoader、ApplicationEventPublisher、ApplicationContext</p><p>  5）、添加BeanPostProcessor【ApplicationListenerDetector】</p><p>  6）、添加编译时的AspectJ；</p><p>  7）、给BeanFactory中注册一些能用的组件；</p><p>​    environment【ConfigurableEnvironment】、</p><p>​    systemProperties【Map<String, Object>】、</p><p>​    systemEnvironment【Map<String, Object>】</p><p>4、postProcessBeanFactory(beanFactory);BeanFactory准备工作完成后进行的后置处理工作；</p><p>  1）、子类通过重写这个方法来在BeanFactory创建并预准备完成以后做进一步的设置</p><p>======================以上是BeanFactory的创建及预准备工作==================================</p><p>5、invokeBeanFactoryPostProcessors(beanFactory);执行BeanFactoryPostProcessor的方法；</p><p>  BeanFactoryPostProcessor：BeanFactory的后置处理器。在BeanFactory标准初始化之后执行的；</p><p>  两个接口：BeanFactoryPostProcessor、BeanDefinitionRegistryPostProcessor</p><p>  1）、执行BeanFactoryPostProcessor的方法；</p><p>​    先执行BeanDefinitionRegistryPostProcessor</p><p>​    1）、获取所有的BeanDefinitionRegistryPostProcessor；</p><p>​    2）、看先执行实现了PriorityOrdered优先级接口的BeanDefinitionRegistryPostProcessor、</p><p>​      postProcessor.postProcessBeanDefinitionRegistry(registry)</p><p>​    3）、在执行实现了Ordered顺序接口的BeanDefinitionRegistryPostProcessor；</p><p>​      postProcessor.postProcessBeanDefinitionRegistry(registry)</p><p>​    4）、最后执行没有实现任何优先级或者是顺序接口的BeanDefinitionRegistryPostProcessors；</p><p>​      postProcessor.postProcessBeanDefinitionRegistry(registry)</p><p>​    再执行BeanFactoryPostProcessor的方法</p><p>​    1）、获取所有的BeanFactoryPostProcessor</p><p>​    2）、看先执行实现了PriorityOrdered优先级接口的BeanFactoryPostProcessor、</p><p>​      postProcessor.postProcessBeanFactory()</p><p>​    3）、在执行实现了Ordered顺序接口的BeanFactoryPostProcessor；</p><p>​      postProcessor.postProcessBeanFactory()</p><p>​    4）、最后执行没有实现任何优先级或者是顺序接口的BeanFactoryPostProcessor；</p><p>​      postProcessor.postProcessBeanFactory()</p><p>6、registerBeanPostProcessors(beanFactory);注册BeanPostProcessor（Bean的后置处理器）【 intercept bean creation】</p><p>​    不同接口类型的BeanPostProcessor；在Bean创建前后的执行时机是不一样的</p><p>​    BeanPostProcessor、</p><p>​    DestructionAwareBeanPostProcessor、</p><p>​    InstantiationAwareBeanPostProcessor、</p><p>​    SmartInstantiationAwareBeanPostProcessor、</p><p>​    MergedBeanDefinitionPostProcessor【internalPostProcessors】、</p><p>​    </p><p>​    1）、获取所有的 BeanPostProcessor;后置处理器都默认可以通过PriorityOrdered、Ordered接口来执行优先级</p><p>7、initMessageSource();初始化MessageSource组件（做国际化功能；消息绑定，消息解析）；</p><p>​    1）、获取BeanFactory</p><p>​    2）、看容器中是否有id为messageSource的，类型是MessageSource的组件</p><p>​      如果有赋值给messageSource，如果没有自己创建一个DelegatingMessageSource；</p><p>​        MessageSource：取出国际化配置文件中的某个key的值；能按照区域信息获取；</p><p>​    3）、把创建好的MessageSource注册在容器中，以后获取国际化配置文件的值的时候，可以自动注入MessageSource；</p><p>​      beanFactory.registerSingleton(MESSAGE_SOURCE_BEAN_NAME, this.messageSource);   </p><p>​      MessageSource.getMessage(String code, Object[] args, String defaultMessage, Locale locale);</p><p>8、initApplicationEventMulticaster();初始化事件派发器；</p><p>​    1）、获取BeanFactory</p><p>​    2）、从BeanFactory中获取applicationEventMulticaster的ApplicationEventMulticaster；</p><p>​    3）、如果上一步没有配置；创建一个SimpleApplicationEventMulticaster</p><p>​    4）、将创建的ApplicationEventMulticaster添加到BeanFactory中，以后其他组件直接自动注入</p><p>9、onRefresh();留给子容器（子类）</p><p>​    1、子类重写这个方法，在容器刷新的时候可以自定义逻辑；</p><p>10、registerListeners();给容器中将所有项目里面的ApplicationListener注册进来；</p><p>​    1、从容器中拿到所有的ApplicationListener</p><p>​    2、将每个监听器添加到事件派发器中；</p><p>​      getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName);</p><p>​    3、派发之前步骤产生的事件；</p><p>11、finishBeanFactoryInitialization(beanFactory);初始化所有剩下的单实例bean；</p><p>  1、beanFactory.preInstantiateSingletons();初始化后剩下的单实例bean</p><p>​    1）、获取容器中的所有Bean，依次进行初始化和创建对象</p><p>​    2）、获取Bean的定义信息；RootBeanDefinition</p><p>​    3）、Bean不是抽象的，是单实例的，是懒加载；</p><p>​      1）、判断是否是FactoryBean；是否是实现FactoryBean接口的Bean；</p><p>​      2）、不是工厂Bean。利用getBean(beanName);创建对象</p><p>​        0、getBean(beanName)； ioc.getBean();</p><p>​        1、doGetBean(name, null, null, false);</p><p>​        2、先获取缓存中保存的单实例Bean。如果能获取到说明这个Bean之前被创建过（所有创建过的单实例Bean都会被缓存起来）</p><p>​          从private final Map<String, Object> singletonObjects = new ConcurrentHashMap<String, Object>(256);获取的</p><p>​        3、缓存中获取不到，开始Bean的创建对象流程；</p><p>​        4、标记当前bean已经被创建</p><p>​        5、获取Bean的定义信息；</p><p>​        6、【获取当前Bean依赖的其他Bean;如果有按照getBean()把依赖的Bean先创建出来；】</p><p>​        7、启动单实例Bean的创建流程；</p><p>​          1）、createBean(beanName, mbd, args);</p><p>​          2）、Object bean = resolveBeforeInstantiation(beanName, mbdToUse);让BeanPostProcessor先拦截返回代理对象；</p><p>​            【InstantiationAwareBeanPostProcessor】：提前执行；</p><p>​            先触发：postProcessBeforeInstantiation()；</p><p>​            如果有返回值：触发postProcessAfterInitialization()；</p><p>​          3）、如果前面的InstantiationAwareBeanPostProcessor没有返回代理对象；调用4）</p><p>​          4）、Object beanInstance = doCreateBean(beanName, mbdToUse, args);创建Bean</p><p>​             1）、【创建Bean实例】；createBeanInstance(beanName, mbd, args);</p><p>​              利用工厂方法或者对象的构造器创建出Bean实例；</p><p>​             加入三级缓存</p><p>​             3）、【Bean属性赋值】populateBean(beanName, mbd, instanceWrapper);</p><p>​            setBeanName</p><p>​        Setbeanclassloader</p><p>​        setBeanFactory</p><p>  <strong>BeanPostProcessor</strong>.postProcessBeforeInitialization</p><p>​           4）、【Bean初始化】initializeBean(beanName, exposedObject, mbd);</p><p>afterPropertiesSet,init</p><p>​      <strong>BeanPostProcessor</strong>.postProcessAfterInitialization</p><p>​         5）、如果单例将创建的Bean添加到缓存中singletonObjects；</p><p>​        ioc容器就是这些Map；很多的Map里面保存了单实例Bean，环境信息。。。。；</p><p>​    5）、注册Bean的销毁方法；</p><p>​    所有Bean都利用getBean创建完成以后；</p><p>​      检查所有的Bean是否是SmartInitializingSingleton接口的；如果是；就执行afterSingletonsInstantiated()；</p><p>12、finishRefresh();完成BeanFactory的初始化创建工作；IOC容器就创建完成；</p><h2 id="Aop源码"><a href="#Aop源码" class="headerlink" title="Aop源码"></a>Aop源码</h2><p>大概分为以下几步：</p><p>spring boot 自动配置AopAutoConfiguration类中带有@EnableAspectJAutoProxy，项目启动即开启对spring AOP的支持，该注解注册了AnnotationAwareAspectJAutoProxyCreator类，该类实现了bean的后置处理器，可以在类创建过程中做一些其他操作</p><p>在bean后置处理器的postProcessBeforeInstantiation方法中，解析切面类，把通知封装成Advisor，并放入缓存advisorsCache中！</p><p>在创建每一个bean时，在bean的后置处理器中的postProcessAfterInitialization方法中，拿到缓存中所有的Advisor，根据切入点PointCut与当前bean做匹配，匹配成功与否决定是否需要创建动态代理！如果匹配到了，则根据实际情况创建动态代理</p>]]></content>
      
      
      <categories>
          
          <category> spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>快手</title>
      <link href="/blog/2023/08/14/26/"/>
      <url>/blog/2023/08/14/26/</url>
      
        <content type="html"><![CDATA[<h2 id="redis锁"><a href="#redis锁" class="headerlink" title="redis锁"></a>redis锁</h2><p>mysql 数据800gb，日志300gb</p><p>es10个索引，每个索引120gb</p><p>redis 6主6从，3gb</p><p>自定义注解</p><pre><code>@Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;)@Retention(RetentionPolicy.RUNTIME)public @interface RefundRedisLock &#123;String key(); // 示例: orderId, param.orderId ()String keyPrefix() default StringUtils.EMPTY; // 示例：order.state (biz prefix string)long limitWaitTimeSeconds() default 3; // 示例 3秒有限等待long expireSeconds() default 30; // 示例：30秒自动释放&#125;</code></pre><p>@Pointcut(“@annotation(com.kuaishou.kwaishop.refund.annotation.RefundRedisLock)”)切入点<br>public void pointcut() {}</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">@Around(&quot;pointcut()&quot;)</span><br><span class="line">public Object doSurround(ProceedingJoinPoint proceedingJoinPoint执行点) throws Throwable &#123;MethodSignature methodSignature = (MethodSignature) proceedingJoinPoint.getSignature();</span><br><span class="line">RefundRedisLock refundRedisLock = methodSignature.getMethod().getAnnotation(RefundRedisLock.class);</span><br><span class="line"> locked = refundRedisLockService.tryLock(lockKey, limitWaitTimeSeconds, expireSeconds);</span><br><span class="line"> 判断当前线程是否已经获得分布式锁,重入次数+1</span><br><span class="line"> retry &lt; maxRetryTimes</span><br><span class="line"> 计算重试获取锁的睡眠等待时间,Min(锁最大释放时间,默认重试间隔时间,获取锁的最大等待时间)</span><br><span class="line"> key-refund.application.service.lock.2319100000001864(orderid)</span><br><span class="line"> value-ip+threadname+id+时间</span><br><span class="line"> if (System.currentTimeMillis() &gt; startTimeMillis + limitWaitTimeSeconds * 1000)</span><br><span class="line"> break;</span><br><span class="line"> return proceedingJoinPoint.proceed();</span><br><span class="line">  if (locked) &#123;</span><br><span class="line">                boolean unlocked = refundRedisLockService.unLock(lockKey);</span><br><span class="line">               判断当前线程是否已经获得分布式锁,重入次数-1</span><br><span class="line">               StringUtils.isEmpty(currentLockValue)</span><br><span class="line">               return false;</span><br><span class="line">               校验目前锁的值是否当前线程持有</span><br><span class="line">               &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>机器断电，锁没释放，造成死锁</p><p>加过期时间，不是和设置锁是原子性的</p><p>业务执行时间过长，锁自动过期了,释放掉了别人的锁</p><p>设置uuid,删除锁的时候判断下是不是自己的</p><p>判断和删除锁要设置成原子性</p><p>最终用redission框架,超时时间默认是30秒,看门狗每隔10s就会进行一次续期,把锁重置成30秒</p><p>加锁其实是通过一段 lua 脚本实现的，这里 <code>KEYS[1]</code> 代表的是你加锁的 key，比如你自己设置了加锁的那个锁 key 就是 “myLock， <code>ARGV[1]</code> 代表的是锁 key 的默认生存时间，默认 30 秒。<code>ARGV[2]</code> 代表的是加锁的客户端的 ID，类似于下面这样：285475da-9152-4c83-822a-67ee2f116a79:52。至于最后面的一个 1 是为了后面可重入做的计数统计，此时，如果客户端 2 来尝试加锁，会如何呢？首先，第一个 if 判断会执行 <code>exists myLock</code>，发现 myLock 这个锁 key 已经存在了。接着第二个 if 判断，判断一下，myLock 锁 key 的 hash 数据结构中，是否包含客户端 2 的 ID，这里明显不是，因为那里包含的是客户端 1 的 ID。所以，客户端 2 会执行：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">return redis.call(&#x27;pttl&#x27;, KEYS[1]);</span><br></pre></td></tr></table></figure><p>返回的一个数字，这个数字代表了 myLock 这个锁 key 的剩余生存时间。返回 null 则说明加锁成功。</p><p>Watch Dog 机制其实就是一个后台定时任务线程，获取锁成功之后，会将持有锁的线程放入到一个 <code>RedissonLock.EXPIRATION_RENEWAL_MAP</code>里面，然后每隔 10 秒 <code>（internalLockLeaseTime / 3）</code> 检查一下，如果客户端 1 还持有锁 key（判断客户端是否还持有 key，其实就是遍历 <code>EXPIRATION_RENEWAL_MAP</code> 里面线程 id 然后根据线程 id 去 Redis 中查，如果存在就会延长 key 的时间），那么就会不断的延长锁 key 的生存时间</p><p>DynamicRateLimiter 对 RateLimiter 封装了一层，底层实现还是 RateLimiter。与 Semaphore 不同的是：Semaphore 限制并发访问的次数，而 RateLimiter 限制并发访问速率。</p><h2 id="RateLimiter"><a href="#RateLimiter" class="headerlink" title="RateLimiter"></a>RateLimiter</h2><p>参考了令牌桶算法。<strong>漏桶算法</strong>的实现往往依赖于队列，请求到达如果队列未满则直接放入队列，然后有一个处理器按照固定频率从队列头取出请求进行处理。如果请求量大，则会导致队列满，那么新来的请求就会被抛弃。<strong>令牌桶算法</strong>则是一个存放固定容量令牌的桶，按照固定速率往桶里添加令牌。桶中存放的令牌数有最大上限，超出之后就被丢弃或者拒绝。当流量或者网络请求到达时，每个请求都要获取一个令牌，如果能够获取到，则直接处理，并且令牌桶删除一个令牌。如果获取不到，该请求就要被限流，要么直接丢弃，要么在缓冲区等待。</p><p>令牌桶限制的是平均流入速率，允许突发请求，只要有令牌就可以处理，支持一次拿多个令牌；漏桶限制的是常量流出速率，即流出速率是一个固定常量值，从而平滑突发流入速率</p><h2 id="ddd"><a href="#ddd" class="headerlink" title="ddd"></a>ddd</h2><p>代码角度：</p><ul><li><p>瘦实体模型：只起到数据类的作用，业务逻辑散落到service，可维护性越来越差；</p></li><li><p>面向数据库表编程，而非模型编程；</p></li><li><p>实体类之间的关系是复杂的网状结构，成为大泥球，牵一发而动全身，导致不敢轻易改代码；</p></li><li><p>service类承接的所有的业务逻辑，越来越臃肿，很容易出现几千行的service类；</p></li></ul><p>分为限界和上下文。限界就是领域的边界，而上下文则是语义环境。 通过领域的限界上下文，我们就可以在统一的领域边界内用统一的语言 进行交流，引入限界上下文（Bounded Context）对问题域进行合理的分 解，识别出核心领域（Core Domain）与子领域（SubDomain），并确定领域的边界以及它 们之间的关系，维持模型的完整性。 2.架构方面：通过分层架构来隔离关注点，尤其是将领域实现独立出来，能够更利于领域 模型的单一性与稳定性</p><ul><li>精细化运营    </li><li>提供可复用的原子能力，后续的换货、投诉等可以复用这些能力，无需重复开发</li></ul><p><strong>资金域</strong></p><p>  <strong>资金域是为了解决在逆向交易过程中交易资金处理。</strong>其核心的作用是收敛各种退资金、退营销的链路以及业务规则。避免资金的处理细节逻辑耦合进入基础退换货逻辑。同时沉淀基础的中台交易逆向资金基础能力，为各种极致保障售后权益提供丰富的资金能力</p><p> <strong>协商（域）</strong></p><p> 这里特指当买家发起某项售后服务后（比如申请退款），需要卖家同意买家的申请，才能退款给买家，如果中间卖家对申请有疑问，可以拒绝买家的申请，或者提起平台介入，进入到买家家，平台三方的纠纷流程，最终完整整个售后服务的过程。</p><p> <strong>诉求（域）</strong></p><p> 指代售后过程中买卖家想要达成的内容，比如针对退款，买家想不退货并且拿回全额货款（100元）。但卖家可以建议是退货才拿起全部退款，或者是不退货，只退部分货款， 沉淀在电商服务中消费者的诉求点，助力业务识别售后过程中消费者的问题点是什么，问题的解决是否顺畅，从而能够在细分场景帮助业务去优化快手电商的整体服务体验</p><p><img src="C:\Users\熊强\AppData\Roaming\Typora\typora-user-images\image-20230821230613406.png" alt="image-20230821230613406" style="zoom: 67%;" /></p><p><strong>1. 用户接口层（Controller层）</strong></p><p>用户接口层负责向用户显示信息和解释用户指令。</p><p><strong>2. 应用层（Service层）</strong></p><p>应用层是很薄的一层，理论上不应该由业务规则或逻辑，主要面向用例和流程相关的操作。也可以完成</p><ul><li>编排多个聚合服务和领域对象完成业务操作；</li><li>调用其他微服务的应用服务，完成微服务之间服务的组合和编排；</li></ul><p>应用服务是在应用层的，它负责服务的组合、编排和转发，负责处理业务用例的执行顺序以及结果的拼装，以粗粒度的服务通过 API 网关向前端发布。还有，应用服务还可以进行安全认证、权限校验、事务控制、发送或订阅领域事件等。</p><p><strong>3. 领域层（domain层）</strong></p><p>领域层的作用是实现企业核心业务逻辑，通过各种校验手段保证业务的正确性。领域层主要体现领域模型的业务能力，它用来表达业务概念，业务状态和业务规则；</p><p>领域层包含聚合根，实体，值对象。领域服务等领域模型中的领域对象；</p><p>领域模型的业务逻辑主要是由实体和领域服务来实现的：</p><ul><li>实体会采用充血模型来实现所有与之相关的业务功能。</li><li>实体和领域对象在实现业务逻辑上是同级的，当领域中的某些功能，单一实体（或者值对象）不能实现时，领域服务就会出马他可以组合聚合内的多个实体（或者值对象），实现复杂的业务逻辑。</li></ul><p><strong>4. 基础层（Repository）</strong></p><p>基础层是贯穿所有层的，它的作用就是为其它各层提供通用的技术和基础服务，包括第三方工具、驱动、消息中间件、网关、文件、缓存以及数据库等。比较常见的功能还是提供数据库持久化。</p><p>基础层包含基础服务，它采用依赖倒置设计，封装基础资源服务，实现应用层、领域层与基础层的解耦，降低外部资源变化对应用的影响。</p><p>在传统架构设计中，由于上层应用对数据库的强耦合，很多公司在架构演进中最担忧的可能就是换数据库了，因为一旦更换数据库，就可能需要重写大部分的代码，这对应用来说是致命的。那采用依赖倒置的设计以后，应用层就可以通过解耦来保持独立的核心业务逻辑。当数据库变更时，我们只需要更换数据库基础服务就可以了，这样就将资源变更对应用的影响降到了最低。</p><p>public abstract class AbstractEvent<Context extends IContext> {</p><p>/**</p><ul><li>执行<br>*/<br>@Override<br>public void doAction(Context context) {<br>// 参数/幂等校验<br>boolean validation = validation(context);<br>if (!validation) {<br>return;<br>}<br>//参数构建<br>buildParam(context);<br>// 执行业务逻辑<br>execute(context);<br>afterExecute(context);<br>}<br>}<br>public class QueryFundEvent extends AbstractEvent<QueryFundContext> {</li></ul><p>@Override<br>public void doAction(QueryFundContext context) {<br>super.doAction(context);<br>}<br>//重写三个方法<br>}</p><p> 策略模式的核心思想是对算法进行封装，委派给不同对象来管理。这样，我们就可以定义一系列算法，将每个算法 封装到具有公共接口的一系列具体策略类中，从而使它们可以灵活替换，并让算法可以在不影响到客户端的情况下发生变化。同时，策略模式仅仅封装算法(包括添加、删除)，但其并不决定在何时使用何种算法，算法的选择由客户端来决定</p><ul><li><p>具体策略类之间可自由切换，由于具体策略类都实现同一个抽象策略接口，所以它们之间可以自由切换。</p></li><li><p>符合“开闭原则”，扩展增加一个新策略时只需添加一个具体策略类即可，不需要改变原有的代码。</p></li><li><p>避免使用多重条件选择语句(if else)，充分体现面向对象设计思想</p><p>缺点</p></li><li><p>客户端必须知道所有的具体策略类，并理解不同具体策略的区别、自行决定使用哪一个策略类。（这一点可以通过本文介绍的方案解决）</p></li><li>策略模式将产生很多具体策略类，在一定程度上增加了系统中类的个数</li></ul>]]></content>
      
      
      <categories>
          
          <category> 快手 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 快手 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring三级缓存</title>
      <link href="/blog/2023/08/14/1/"/>
      <url>/blog/2023/08/14/1/</url>
      
        <content type="html"><![CDATA[<p><img src="https://img.bestxq.live//20230425173456.png" alt="img"></p><p><img src="C:\Users\熊强\Pictures\学习资料\20230425173305.png" alt="img">如果 Spring 选择二级缓存来解决循环依赖的话，那么就意味着所有 Bean 都需要在实例化完成之后就立马为其创建代理，而 Spring 的设计原则是在 Bean 初始化完成之后才为其创建代理。所以，Spring 选择了三级缓存。但是因为循环依赖的出现，导致了 Spring 不得不提前去创建代理，因为如果不提前创建代理对象，那么注入的就是原始对象，这样就会产生错误。</p><ul><li>对于构造器注入产生的循环依赖，可以使用 <code>@Lazy</code> 注解，延迟加载。</li><li>对于多例 Bean 和 <code>prototype</code> 作用域产生的循环依赖，可以尝试改为单例 Bean</li></ul>]]></content>
      
      
      <categories>
          
          <category> spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hr面</title>
      <link href="/blog/2023/08/14/13/"/>
      <url>/blog/2023/08/14/13/</url>
      
        <content type="html"><![CDATA[<p>面试官您好，我叫熊强，现在是南昌大学软件工程应届生。大一的时候，主要学习了Java框架栈，mysql，redis，mq，ssm,SpringCloud常用组件,看一些常用框架的源码。大二开始学一些云原生相关的知识，docker,k8s，开始做一些项目，小到个人博客，微软云+docker，电商项目都做过，已经成功用k8s部署到甲骨文的三个云主机节点,安装KubeSphere来持续集成持续交付。大三上半年去美团公司实习，主要从事的是美团到家研发平台的后端开发工作，主要负责美团电商、交易、广告相关功能模块的研发及优化工作，我主要是用一些美团自研的组件来完成一些需求。下半年在快手实习，主要在电商技术部-交易中心负责售后相关模块的研发及优化工作，做了一个买家首页红点查询开发的需求，将db中的数据通过<strong>kbus</strong>同步到es，实现自定义锁和限流组件,对标pdd，在下单返现金，到门槛后可以提现活动中，提供<strong>逆向规则</strong>，敲定等比例退方案 ，降低业务资损风险，提升用户体验， 用户端逆向交易资金表达的重构，售后链路各环节实现了与正向交易钱款、营销资产信息拉齐，新增展示了退营销资产信息，清晰透传各明细项分摊结果，并对后续各类营销玩法升级打下基础，提升迭代效率及用户体验， 减少用户针对资金的疑惑和cpo</p><h2 id="为什么选专业选了计算机"><a href="#为什么选专业选了计算机" class="headerlink" title="为什么选专业选了计算机"></a>为什么选专业选了计算机</h2><ol><li><p>市场需求：计算机专业是目前市场需求最大的专业之一，计算机技术在各个领域都有广泛的应用，如互联网、金融、医疗、教育等。因此，选择计算机专业可以增加就业机会和职业发展空间。</p></li><li><p>技术发展：计算机技术是一种快速发展的技术，每年都有新的技术和应用出现。选择计算机专业可以接触到最新的技术和应用，学习和掌握这些技术可以提高自己的竞争力和创新能力。</p></li><li><p>兴趣爱好：有些人对计算机技术和编程有浓厚的兴趣和爱好，选择计算机专业可以满足自己的兴趣和爱好，享受编程和技术带来的乐趣和成就感。</p></li><li><p>薪资待遇：计算机专业的薪资待遇相对较高，尤其是在互联网和科技公司工作的薪资更高。因此，选择计算机专业可以获得更好的薪资待遇和福利。</p></li></ol><h2 id="未来3-5年的规划是什么？"><a href="#未来3-5年的规划是什么？" class="headerlink" title="未来3-5年的规划是什么？"></a>未来3-5年的规划是什么？</h2><p>前期，熟悉工作环境，快速融入团队，熟悉团队的业务，保质保量完成团队交给我的任务，总体看一下项目的架构，在导师的帮助下参与一些模块，将所学知识应用于实践中。这有助于加深对 Java 开发流程和项目管理的理解，同时提升自己的编码和调试能力，慢慢成长学习。</p><p>中期，专注于某一个领域，独立工作一件方向，关注新兴的技术趋势，学习并实践相关技术，探索其在实际应用中的潜力，与自己组的业务相结合，开发出创新的解决方案</p><p>后期，发现团队的业务需求以及技术需求，推动团队的整体发展。注重系统设计和架构能力的提升，学习设计模式、架构模式和高性能编程等。能够设计出可扩展、高效和可维护的系统，解决实际问题并优化性能。</p><h2 id="为什么选择我们公司呢"><a href="#为什么选择我们公司呢" class="headerlink" title="为什么选择我们公司呢"></a>为什么选择我们公司呢</h2><p>拼多多在电商领域算是TOP级的公司，其业务规模庞大，需要大量的技术支持。作为一名求职者，我相信在这样的公司工作，我将有机会参与到先进的技术研发和创新的团队中。技术氛围很好，有丰富的文档和课程视频可以学习，同事和导师也很悉心地教我，我希望能够在美团公司实现我的职业目标，与优秀的团队合作，共同推动公司的发展和成长</p><h2 id="你觉得你有什么缺点？"><a href="#你觉得你有什么缺点？" class="headerlink" title="你觉得你有什么缺点？"></a>你觉得你有什么缺点？</h2><ol><li>喜欢追求细节导致项目未能按期完成。通过实践管理能力改变工作方式，在完成项目的情况下在改善细节。</li><li>不止如何拒绝，同事要求帮忙一概揽下，影响自己的工作进度。通过多任务处理能力设定优先顺序，以该优先顺序表向求助同事展示自己手上的工作，并给其一个自己在何时可以给予帮助的时间估计，让求助人自行决定是否求助。</li><li><p>我觉得我不够自信，我说的是技术方面的自信，作为一个实习生我不太敢质疑，总会觉得是自己的问题。</p></li><li><p>我觉得我有点操之过急了，老是叫导师给我安排任务，老是和我说年轻人，不要心急，慢慢来</p></li></ol><h2 id="实习对你的帮助"><a href="#实习对你的帮助" class="headerlink" title="实习对你的帮助"></a>实习对你的帮助</h2><ol><li><strong>实践经验：</strong> 实习是将课堂学习应用于实际项目的绝佳机会。你将有机会参与开发真实的应用程序，从中学习如何处理实际问题，应对挑战并实现解决方案。</li><li><strong>技术深入：</strong> 在实习期间，你将有机会深入了解Java后端技术栈。你可以学习使用各种框架、库和工具，理解它们的工作原理，并在实际项目中应用它们。</li><li><strong>团队合作：</strong> 在团队环境中工作可以教会你如何与其他开发人员、设计师和产品经理合作。你将学会与团队成员协作、交流和解决问题。</li><li><strong>熟悉流程：</strong><img src="C:\Users\熊强\Pictures\学习资料\drawio(6).svg" alt="drawio(6)" style="zoom: 200%;" /></li><li><strong>人脉拓展：</strong> 在实习中，你会遇到许多同行和行业专业人士。建立起这些人脉关系有助于你未来的职业发展。</li></ol><h2 id="实习中遇到的难点，怎么解决的"><a href="#实习中遇到的难点，怎么解决的" class="headerlink" title="实习中遇到的难点，怎么解决的"></a>实习中遇到的难点，怎么解决的</h2><ol><li>一开始刚接触项目的时候 对于项目整体逻辑的不了解，不知道如何很快地熟悉业务，对于某些方面的知识掌握较少，有一些完全没有了解的知识点，不熟悉的地方 单独拆分出来 涉及到的模块 知识点 系统的去学习 关联起来 对于不熟悉的业务，虚心请教导师和同事，我觉得算是一直在不断完善和提升自己吧实习阶段可能会遇到自己不熟悉的技术或任务。解决方法是积极主动地学习和研究，阅读公司文档、教程，向同事或导师请教，提升自己的技能和知识。</li><li>没有明确的指导和反馈：有时候实习生可能会感到缺乏明确的指导和反馈。解决方法是主动与导师或上级沟通，明确任务目标和期望，寻求反馈和建议，及时汇报工作进展，以便及时调整和改进自己的工作。</li><li>领导突然安排比较紧急的事情。时间紧任务需求不明确。 1.我首先要做找好对接人，清楚需求细节、具体的需求上线的时间点。 2.对需求紧急排期 看在一个极短的时间内需要好多人力才能完成改需求 3.在研发过程中 注意时间点的把控好，对领导 及时反馈进展，对客户要注重反馈已完成的事项 待完成事项和时间等问题</li></ol><h2 id="学历？"><a href="#学历？" class="headerlink" title="学历？"></a>学历？</h2><p>我认为程序员这门职位技术是大于学历的，是否毕业于名牌院校不重要，重要的是有能力完成您交给我的工作，我学习了三年的java知识，掌握的技能完全可以胜任贵公司现在工作，而且我比一些名牌院校的应届毕业生的动手能力还要强，我想我更适合贵公司这个职位。</p><h2 id="对加班的看法？"><a href="#对加班的看法？" class="headerlink" title="对加班的看法？"></a>对加班的看法？</h2><p>表现出对工作的承诺和责任感的方式。相信通过额外的努力和时间投入，他们可以提高工作绩效，取得更好的成果。对于创业者和热衷于事业成功的人来说</p><p>如果是工作需要我会义不容辞加班。我现在单身，没有任何家庭负担，可以全身心的投入工作。但同时，我也会提高工作效率，减少不必要的加班</p><h2 id="与上级意见不一致时，你将怎么办？"><a href="#与上级意见不一致时，你将怎么办？" class="headerlink" title="与上级意见不一致时，你将怎么办？"></a>与上级意见不一致时，你将怎么办？</h2><p>我会好好和上级沟通，向上级说明我的意见和担心的问题，对于一般问题，我会 服从上级的意见。但是，如果上级的意见可能会损失公司重大利益的时候，我希望能和更高层领导交流沟通。</p><h2 id="薪资"><a href="#薪资" class="headerlink" title="薪资"></a>薪资</h2><p>想请问一下贵司的薪资构成</p><p>您好，<br>在面试之前我了解到行业岗位的平均薪资是25k，根据您刚才介绍的薪资情况，结合自身的经验和能力，我的<br>期望薪资是25k;但是，由于各个公司的薪资结构不一样，所以我也要结合咋们的薪资结构再看</p><p>您好，目前的薪资情况和我的预期++有一定差距，所以还是想再争取下，，像我在之前的几段实习中，锻炼了我的能力和岗位技能，有信心可以将这些经验力和岗位技能，更快上手，快速迁移到现在的工作中，而且通过几轮面试下来，我感觉咋们无论是面试官还是hr，都让我觉得团队氛围挺好的，做的方向也是自己喜欢的，薪资虽然不是我选择公司的唯一标准，但是我还是希望全身心地投入到工作中，减少不必要的干扰，某公司开的薪资比你们这里多1万钱，但是他们那边做的东西，没有咋们那边那么契合，但是1万钱对我来说也挺多的了，甚至能抵消我的房租，哪怕你这边稍微减少一点差距，我想都不想直接把他们拒了，其实我还是属于挺纠结的阶段，我知道咋们公司也是有预算的</p><p>看来你这边也是帮我争取薪资了，我也特别感谢你帮我争取</p><p>那行吧，我也是觉得您这边的业务更符合我，让我发挥自己的长处，</p><p>我目前也有拿到其他公司的一些offer,对比了下，虽然我很想来这边，但薪资确实差得有点远，可不可以请您再帮我争取一下，实在争取不了，那也不为难了。</p><h2 id="你觉得你个性上最大的优点是什么？"><a href="#你觉得你个性上最大的优点是什么？" class="headerlink" title="你觉得你个性上最大的优点是什么？"></a>你觉得你个性上最大的优点是什么？</h2><p>沉着冷静、条理清楚、立场坚定、顽强向上、乐于助人和关心他人、适应能力和幽默感、乐观和友爱、技术狂热、学习能力强、为人谦和。</p><h2 id="如果你的工作出现失误，给本公司造成经济损失，你认为该怎么办？"><a href="#如果你的工作出现失误，给本公司造成经济损失，你认为该怎么办？" class="headerlink" title="如果你的工作出现失误，给本公司造成经济损失，你认为该怎么办？"></a>如果你的工作出现失误，给本公司造成经济损失，你认为该怎么办？</h2><p>回答建议（仅供参考）：<br>① 我本意是为公司努力工作，如果造成经济损失，我认为首要的问题是想方设法去弥补或挽回经济损失。如果我无能力负责，希望单位帮助解决；<br>② 是责任问题。分清责任，各负其责，如果是我的责任，我甘愿受罚；如果是一个我负责的团队中别人的失误，也不能幸灾乐祸，作为一个团队，需要互相提携共同完成工作，安慰同事并且帮助同事查找原因总结经验。<br>③ 总结经验教训，一个人的一生不可能不犯错误，重要的是能从自己的或者是别人的错误中吸取经验教训，并在今后的工作中避免发生同类的错误。检讨自己的工作方法、分析问题的深度和力度是否不够，以致出现了本可以避免的错误。</p><h2 id="你和别人发生过争执吗？你是怎样解决的？"><a href="#你和别人发生过争执吗？你是怎样解决的？" class="headerlink" title="你和别人发生过争执吗？你是怎样解决的？"></a>你和别人发生过争执吗？你是怎样解决的？</h2><p>在争执发生时保持冷静非常重要。如果情绪高涨，很容易做出冲动或不理智的决定。尽量控制自己的情绪，保持冷静并清晰地思考问题。倾听对方的观点和意见是解决争执的关键。认真倾听可以表明你尊重对方，并且有助于你理解对方的立场。不要打断对方，给予对方充分的表达意见的机会。一旦对方表达完毕，你可以清晰、坦诚地表达自己的观点。避免使用攻击性语言或过于情绪化的措辞，而是试图以合作和解决问题的方式表达自己的立场。</p>]]></content>
      
      
      <categories>
          
          <category> hr </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hr </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kbus</title>
      <link href="/blog/2023/08/06/27/"/>
      <url>/blog/2023/08/06/27/</url>
      
        <content type="html"><![CDATA[<p>传统同步或者异步写到其他存储</p><p>多写入端，无法保证全部写入事务性，准确性，顺序性受限网络、不同终端性能、复杂拓扑等问题，对生产系统产生耦合性太强。性能也受到严重制约跨机房，下游变更，业务修改等都会对生产系统产生影响</p><p>使用kbus数据总线异步处理数据流能更灵活的应对各种架构演变，解耦生产系统和消费系统。以及跨机房，甚至跨语言带来的各种复杂性。</p><ol><li><p>使用服务化方式发布，业务端和中间件完全解耦合。</p><blockquote><ul><li>只暴露给用户最简单、最易用的消费功能API，减少用户的学习成本，使用成本</li><li>业务不需要频繁升级就可以享受各种KBus的新优化和新功能</li><li>在公司内部出现大促活动或者其他大的基础设施变更时，涉及的流量/机器调度、服务保障等都不需要用户过多介入。涉及到多机房异地机房变更等各种底层设施变化也都平滑给用户提供解决方案，让用户无感知</li></ul></blockquote></li><li><p>一处生产，处处消费设计理念。</p><blockquote><ul><li>用户不需要关心数据输入源，只需要KBus这边启动server端，用户可以在任何机房启动消费</li><li>可进行跨AZ/Region消费。用户不需要在需要消费的AZ或region部署生产源就可以直接消费，只要有一处源头生产端即可</li></ul></blockquote></li><li><p>提供用户可定制的托管化通用消费方案（如同步mysql到缓存，同步mysql到es，消费mysql到大数据等托管服务）</p><blockquote><ul><li>用户通过KBus admin管理台配置平台提供的通用消费方案，即可直接启动托管消费。不需要用户写代码，也不需要用户上线服务。保证在半天内上线用户通用功能</li></ul></blockquote></li><li><p>提供事务性消费支持。用户可按照事务维度进行消费，保证业务在同一事务内的数据可联动处理业务逻辑。</p></li><li><p>提供给用户高性能多样性的顺序消费方案。可以让用户在进行顺序性消费要求时，解决用户只能单机顺序消费一个数据库的性能瓶颈。KBus提供在服务端定制多样性顺序生产，下游可多个实例对数据顺序消费，提供客户端的消费能力上限。</p></li><li><p>KBus提供根据时间回溯消费功能。如可以让业务对回溯因为上线导致消费不对进行回溯一段时间内的内容</p><h2 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h2><p><strong>先删除 cache ，后更新 db</strong> </p><p>请求 1 先把 cache 中的 A 数据删除 -&gt; 请求 2 从 db 中读取数据-&gt;请求 1 再把 db 中的 A 数据更新-&gt;请求 2将数据 A 写入 cache</p><p><strong>先更新 db ，后删除cache</strong></p><p>请求 1 从 db 读数据 A-&gt; 请求 2 更新 db 中的数据 A（此时缓存中无数据 A ，故不用执行删除缓存操作 ） -&gt; 请求 1 将数据 A 写入 cache</p><p>延迟X毫秒删除缓存主要的意义在于：1. 有可能之前缓存里写入了脏数据，删除缓存可以清空掉脏数据；2. 删除缓存后，下次读会回源db，因为延迟了x毫秒才删除，这x毫秒主要是保证db主从已经完成同步，这时候再从从库回源依然能读到正确的数据</p><h2 id="kubs"><a href="#kubs" class="headerlink" title="kubs"></a>kubs</h2><p>产生不一致的过程为:</p><ol><li><p>请求A，发起读请求，发现缓存中没有数据</p></li><li><p>请求A，从DB进行回源，从DB中读到的数据为V1</p></li><li><p>请求B，发起写请求，将DB中的数据更新为V2</p></li><li><p>KBUS，消费到更新的binlog，将缓存更新为V2</p></li><li><p>请求A，将从DB回源读到的数据V1，写回redis</p><p>用setnx指令来替代set指令</p></li></ol></li></ol><p><img src="C:\Users\熊强\Pictures\学习资料\2ldvif.5207d10c355d496f.png" alt="kbus-overview-3"></p>]]></content>
      
      
      <categories>
          
          <category> kbus </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kbus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高并发</title>
      <link href="/blog/2023/07/08/25/"/>
      <url>/blog/2023/07/08/25/</url>
      
        <content type="html"><![CDATA[<p>那我以美团外卖演进路的高并发和高可用来举例子吧，外卖业务其实已经非常是一个非常普遍存在的一个这种业务了，然后呢它的其实主要就是围绕我们线上的一个商品交易以及一个及时的一个配送服务搭建一个o2o的综合电商的交易平台,外卖业务的一个整个的一个增长的一个里程碑，也就是发展的历程，然后业务呢于一三年的十一月上线，然后在通过一年的发展我们在一四年的十一月达到了一个一订单突破百万的这么一个量级，针对于我们业务的每一个阶段的一些业务的特点，然后系统呢也进行了相应的一些迭代啊，主要是包括四个阶段啊，分别是起步阶段，微服务化阶段，以及精细化阶段，以及我们当前的一个set阶段</p><h2 id="起步阶段"><a href="#起步阶段" class="headerlink" title="起步阶段"></a>起步阶段</h2><p>我们简单来看一下起步阶段的一个特点啊为起步阶段呢，主要是我们是主要是对对这个业务进行一个探索看看这个业务到底发展方向对不对好，我们系统比较单一 ，通用而且比较复杂的外卖servise的一个jar包来供各个前端的应用加载进来来提供服务，核心优化点就是lbs算法，缓存还有程序执行中的一些异步，批量的一些操作</p><h2 id="微服务化阶段"><a href="#微服务化阶段" class="headerlink" title="微服务化阶段"></a>微服务化阶段</h2><p>为什么要提出这个阶段，就是因为我们这个业务在14年15年我们明确了业务的方向，并且我们业务的方向是可以稳定向前推进的，这个时候我们需要启动功能的逐渐完善，我们的订单也随之快速增长，业务越来越复杂，然后由于我们的系统那是刚才我们介绍的全是放在 在一个大jar里面来完成，所有的逻辑都耦合在一个jar包里，这样那就会导致 影响开发的迭代效率，系统是极容易出现问题的，核心改进点就是微服务，消息驱动和分库分表，我们针对业务不同场景的分析，线上业务和管理业务，线上业务又针对不同的领域比如商品，订单，广告等进行一个领域的拆分 在拆厂完之后呢我们的业务又有不同的服务特征，比如实时数据，历史数据，具体实施的时候我们先拆分出服务来，然后逐渐地把流量先引过来，保证我们线上的功能是稳定的，对于实时的访问哦是通过rpc的方式来调用，而对于上下游比较长的通过消息的方式来进行流转，避免微服务间过度耦合，方便业务进行扩展，但是随着订单的持续增长，数据库的压力比较大，像一些读压力过大的化我们可以通过增加从库，但是写场景，我们又提出了分库分表，以订单为例，为了支持不同维度的查询，按照门店，用户，订单id三个维度冗余</p><h2 id="精细化阶段"><a href="#精细化阶段" class="headerlink" title="精细化阶段"></a>精细化阶段</h2><p>随着体量越来越大，对稳定性的要求越来越高，核心改进点，研发流程规范;中间件升级;服务柔性调用&amp;服务限流;<br>压测&amp;监控&amp;降级SOP</p><p><img src="C:\Users\熊强\Pictures\学习资料\QQ截图20230708222316.png" alt="QQ截图20230708222316"></p><h2 id="set化"><a href="#set化" class="headerlink" title="set化"></a>set化</h2><p><img src="C:\Users\熊强\Pictures\学习资料\微信截图_20230708224226.png" alt="微信截图_20230708224226"></p><p>![微信截图_20230708224226](C:\Users\熊强\Pictures\学习资料\微信截图_20230708224226.png</p><p><img src="C:\Users\熊强\Pictures\学习资料\QQ截图20230708224310.png" alt="QQ截图20230708224310"></p>]]></content>
      
      
      <categories>
          
          <category> 高并发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>swan</title>
      <link href="/blog/2023/07/02/24/"/>
      <url>/blog/2023/07/02/24/</url>
      
        <content type="html"><![CDATA[<p>Swan 是美团的分布式事务事务，推行 SOA 的过程，会带来大量的服务拆分和数据库拆分，造成跨服务调用和跨库操作的需求日益增多。这些场景下单次业务操作通常需要更新多个数据库、调用上下游多个服务才得以完成，单库事务已不再能解决问题，需要引入分布式事务解决方案</p><p><img src="C:\Users\熊强\Pictures\学习资料\QQ截图20230704224720.png" alt="QQ截图20230704224720"></p><h2 id="TCC"><a href="#TCC" class="headerlink" title="TCC"></a>TCC</h2><p>一个 TCC 事务由三个方法组成，分别是 Try、Confirm 和 Cancel，三者分别定义了针对某种资源的预留（也叫冻结或者锁定）、提交和回滚逻辑，其中只有一阶段 Try 操作是可能需要加锁的，Confirm 与 Cancel 方法体应该尽可能简单，仅仅涉及资源的提交和回滚逻辑，不再做任何资源锁定、重复检查等逻辑。</p><p>TCC 三个方法描述：</p><ul><li><strong>Try：资源预留/锁定操作</strong>，是事务发起方调用服务提供方的try方法来锁定业务需要的所有资源。这里通常会通过加锁，完成资源的隔离（一阶段成功之后每个 TCC 事务都已经拥有了自己独占的一份资源）</li><li><strong>Confirm：确认执行业务逻辑操作</strong>，这里使用的资源一定是 Try 阶段预留的业务资源。在 TCC 事务机制中认为，如果在try阶段能正常的预留资源，那么 Confirm 和 Cancel 阶段一定能完整正确的提交。Confirm  阶段也可以看成是对 Try 阶段的一个补充，Try + Confirm 一起组成了一个完整的业务逻辑。在一篇文章中看到过这么一个说法，我觉得挺对的：TCC机制将传统事务机制中的业务逻辑一分为二，拆分后保留的部分即为初步操作（Try）；而分离出的部分即为确认操作（Confirm），被延迟到事务提交阶段执行。（不再需要加锁，直接提交资源修改）</li><li><strong>Cancel：取消执行业务逻辑</strong>。但这和普通的补偿性事务不一样的地方是，Cancel 阶段并没有真正的回滚业务（因为 Try 阶段并没有真正执行业务），而是释放之前锁定的资源。（不再需要加锁，直接解锁占用的资源）</li></ul><p>以“扣钱”场景为例，在接入 TCC 前，对 A 账户的扣钱，只需一条更新账户余额的 SQL 便能完成，这时候数据库表结构中可能仅有一个字段 amount 字段用来标识余额</p><p>但是在接入 TCC 之后，用户就需要考虑如何将原来一步就能完成的扣钱操作，拆成两阶段，实现成三个方法，并且保证一阶段 Try  成功的话 二阶段 Confirm 一定能成功。因此，需要在表中新增一个字段 frozen_amount 字段用来标识当前冻结的余额。</p><p>Try：可用余额 100，冻结 30，此时 amount = 70，frozen_amount = 30，同时记录流水表，对前端用户显示文案：当前余额 100，其中 30 处于冻结状态</p><p>Confirm：先检查流水表状态是否正常，如果正常，将 frozen_amount 扣减 30，此时 amount = 70，frozen_amount = 0，逻辑完成，对前端用户显示文案：支付成功！</p><p>Cancel：说明一阶段异常，先检查下流水表看是否正常完成一阶段预留逻辑，如果正常则将 frozen_amount 扣减 30，加回到 amount 字段中，此时 amount = 100，frozen_amount = 0，逻辑完成，对前端用户显示文案：取消支付成功！</p><h2 id="Saga"><a href="#Saga" class="headerlink" title="Saga"></a>Saga</h2><p>Saga 模式是一种分布式异步事务，保证最终一致性事务，隶属于柔性事务的一种。</p><p>每个 Saga 由一系列 sub-transaction Ti （子事务、也叫分支事务）组成，每个 Ti  都有对应的补偿动作 Ci，补偿动作用于撤销 Ti 造成的结果。可以看到，和 TCC 相比，Saga 没有“资源预留”动作，它的 Ti 就是直接提交到库。Saga 事务的执行顺序有两种：</p><p>（正常情况下，一阶段流程）T1, T2, T3, …, Tn</p><p>（异常情况下，一阶段 + 补偿流程）T1, T2, …, Tj, Cj,…, C2, C1，其中 0 &lt; j &lt;= n</p><p>Saga 定义了两种恢复策略：</p><p>backward recovery，逆序回滚：即上面提到的第二种执行顺序，其中 j 是发生错误的 sub-transaction，这种做法的效果是撤销掉之前所有成功的 sub-transation，使得整个 Saga 的执行结果撤销。</p><p>forward recovery，向前重试：适用于必须要成功的场景，执行顺序是类似于这样的：T1, T2, …, Tj (失败), Tj (重试),…, Tn，其中 j 是发生错误的 sub-transaction，该情况下不需要 Ci。</p><p><img src="C:\Users\熊强\Pictures\学习资料\drawio(3" alt="drawio(3)">.svg)</p><p>如果创建订单异常，一般情况下，我们期望能够继续重试业务逻辑，而不是直接丢弃订单向用户返回失败，则整个流程应该向前继续重试：</p><p>createOrder（异常） -&gt; createOrder -&gt; payOrder -&gt; deliverProduct</p><p>总会出现一些特殊情况比如 Ci 的代码有 bug、服务长时间崩溃等，这个时候就需要人工介入了，Swan 会有最大重试次数这个阈值，超出次数会熔断告警，用户可以在管理平台人工处理。</p><h2 id="TXC"><a href="#TXC" class="headerlink" title="TXC"></a><strong><em>TXC</em></strong></h2><p>全称叫 <strong><em>（Taobao Transaction Constructor）</em></strong>，是阿里中间件团队 2014 年在集团内部推出的分布式事务解决方案，与 TCC 不同的是，TXC 通过框架代理底层数据源、拦截具体的 SQL 语句、存储数据操作前后快照、引入全局锁保证事物间写隔离、框架自动生成反向补偿 SQL 语句等方法，真正做到对上层业务屏蔽底层分布式事务细节，使得用户可以像使用本地事务一样去使用分布式事务，最大程度降低了分布式事务的使用成本</p><p>服务发起方向 TC 集群注册开启全局事务，TC 集群返回给事务发起方一个全局事务 XID</p><p>发起方调用业务请求，流量流经的 GroupDataSource 和 ShardDataSource 均作为该全局事务的参与方</p><p>每当流量经过一个数据源时，都会在本地存储前后镜像数据，并向 TC 集群注册分支和全局事务锁</p><p>TC 集群侧维护了该全局事务下的所有分支事务记录</p><p>发起方会视业务请求是否抛异常向 TC 集群要求提交或者回滚全局事务</p><p>TC 集群回调每个数据源完成二阶段补偿</p><p>可以看出，多数据源跨库事务其实是将单数据源跨库事务包装成了一个个参与方，并通过 TC 集群完成二阶段补偿，其实内部是复用的单数据源跨库事务的功能，在此基础上新增了同 TC 集群交互的通信模块</p><p><img src="C:\Users\熊强\Pictures\学习资料\drawio(4" alt="drawio(4)">.svg)</p>]]></content>
      
      
      <categories>
          
          <category> swan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> swan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zebra</title>
      <link href="/blog/2023/07/02/23/"/>
      <url>/blog/2023/07/02/23/</url>
      
        <content type="html"><![CDATA[<p> Zebra是一个基于JDBC API协议上开发出的高可用、高性能的<strong>数据库访问层</strong>解决方案,简化了读写分离、分库分表的开发工作，使得业务方在分库分库、读写分离的情况下，依然可以像操作单个库那样去操作，屏蔽底层实现的复杂性，对业务透明。</p><h1 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h1><p>在单台mysql实例的情况下，所有的读写操作都集中在这一个实例上。当读压力太大，单台mysql实例扛不住时，此时DBA一般会将数据库配置成集群，一个master(主库)，多个slave(从库)，master将数据通过binlog的方式同步给slave，可以将slave节点的数据理解为master节点数据的全量备份</p><ol><li><strong>对sql类型进行判断。</strong>如果是select等读请求，就走从库，如果是insert、update、delete等写请求，就走主库。</li><li><strong>主从数据同步延迟问题。</strong>因为数据是从master节点通过网络同步给多个slave节点，因此必然存在延迟。因此有可能出现我们在master节点中已经插入了数据，但是从slave节点却读取不到的问题。对于一些强一致性的业务场景，要求插入后必须能读取到，因此对于这种情况，我们需要提供一种方式，让读请求也可以走主库，而主库上的数据必然是最新的。</li><li><strong>事务问题。</strong>如果一个事务中同时包含了读请求(如select)和写请求(如insert)，如果读请求走从库，写请求走主库，由于跨了多个库，那么jdbc本地事务已经无法控制，属于分布式事务的范畴。而分布式事务非常复杂且效率较低。因此对于读写分离，目前主流的做法是，事务中的所有sql统一都走主库，由于只涉及到一个库，jdbc本地事务就可以搞定。</li><li><strong>高可用问题。</strong>主要包括：</li></ol><ul><li><strong>新增slave节点：</strong>如果新增slave节点，应用应该感知到，可以将读请求转发到新的slave节点上。</li><li><strong>slave宕机或下线：</strong>如果其中某个slave节点挂了/或者下线了，应该对其进行隔离，那么之后的读请求，应用将其转发到正常工作的slave节点上。</li><li><strong>master宕机：</strong>需要进行主从切换，将其中某个slave提升为master，应用之后将写操作转到新的master节点上。</li></ul><h1 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h1><p>读写分离，主要是为了数据库读能力的水平扩展。而分库分表则是为了写能力的水平扩展。</p><ul><li><p><strong>sql解析：</strong>首先对sql进行解析，得到需要插入的四条记录的id字段的值分别为1,2,3,4</p></li><li><p><strong>sql路由：</strong>sql路由包括库路由和表路由。库路由用于确定这条记录应该插入哪个库，表路由用于确定这条记录应该插入哪个表。</p></li><li><p><strong>sql改写：</strong>上述批量插入的语法将会在 每个库中都插入四条记录，明显是不合适的，因此需要对sql进行改写，每个库只插入一条记录。</p></li><li><p><strong>sql执行：</strong>一条sql经过改写后变成了多条sql，为了提升效率应该并发的到不同的库上去执行，而不是按照顺序逐一执行</p></li><li><p><strong>结果集合并：</strong>每个sql执行之后，都会有一个执行结果，我们需要对分库分表的结果集进行合并，从而得到一个完整的结果。</p><h2 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h2></li></ul><p>服务端代理(proxy：代理数据库)</p><p>​      我们独立部署一个代理服务，这个代理服务背后管理多个数据库实例。而在应用中，我们通过一个普通的数据源(c3p0、druid、dbcp等)与代理服务器建立连接，所有的sql操作语句都是发送给这个代理，由这个代理去操作底层数据库，得到结果并返回给应用。在这种方案下，分库分表和读写分离的逻辑对开发人员是完全透明的。</p><p>不论你用的php、java或是其他语言，都可以支持。原因在于数据库代理本身就实现了mysql的通信协议，你可以就将其看成一个mysql 服务器。mysql官方团队为不同语言提供了不同的客户端驱动，如java语言的mysql-connector-java，python语言的mysql-connector-python等等。因此不同语言的开发者都可以使用mysql官方提供的对应的驱动来与这个代理服务器建通信</p><p>客户端代理(datasource：代理数据源)</p><p>​      应用程序需要使用一个特定的数据源，其作用是代理，内部管理了多个普通的数据源(c3p0、druid、dbcp等)，每个普通数据源各自与不同的库建立连接。应用程序产生的sql交给数据源代理进行处理，数据源内部对sql进行必要的操作，如sql改写等，然后交给各个普通的数据源去执行，将得到的结果进行合并，返回给应用。数据源代理通常也实现了JDBC规范定义的API，因此能够直接与orm框架整合。在这种方案下，用户的代码需要修改，使用这个代理的数据源，而不是直接使用c3p0、druid、dbcp这样的连接池。</p><p>更加轻量，可以与任何orm框架整合</p><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><p>数据表拆分的首要原则，就是要尽可能找到数据表中的数据在业务逻辑上的主体，并确定大部分（或核心的）数据库操作都是围绕这个主体的数据进行，然后可使用该主体对应的字段作为分表键，进行分库分表。</p><p>业务逻辑上的主体，通常与业务的应用场景相关，下面的一些典型应用场景都有明确的业务逻辑主体，可用于分表键：</p><ul><li>面向用户的互联网应用，都是围绕用户维度来做各种操作，那么业务逻辑主体就是用户，可使用用户对应的字段作为分表键；          </li><li>侧重于卖家的电商应用，都是围绕卖家维度来进行各种操作，那么业务逻辑主体就是卖家，可使用卖家对应的字段作为分表键；</li></ul><p>以此类推，其它类型的应用场景，大多也能找到合适的业务逻辑主体作为分表键的选择。</p><p>如果确实找不到合适的业务逻辑主体作为分表键，那么可以考虑下面的方法来选择分表键：</p><ul><li>根据数据分布和访问的均衡度来考虑分表键，尽量将数据表中的数据相对均匀地分布在不同的物理分库/分表中，适用于大量分析型查询的应用场景（查询并发度大部分能维持为1）；</li><li>按照数字（字符串）类型与时间类型字段相结合作为分表键，进行分库和分表，适用于日志检索类的应用场景。</li></ul><div class="table-container"><table><thead><tr><th style="text-align:left">分表方式</th><th style="text-align:left">解释</th><th style="text-align:left">优点</th><th style="text-align:left">缺点</th><th style="text-align:left">试用场景</th><th style="text-align:left">版本要求</th></tr></thead><tbody><tr><td style="text-align:left">Hash</td><td style="text-align:left">拿分表键的值Hash取模进行路由。最常用的分表方式。</td><td style="text-align:left">数据量散列均衡，每个表的数据量大致相同。请求压力散列均衡，不存在访问热点</td><td style="text-align:left">一旦现有的表数据量需要再次扩容时，需要涉及到数据移动，比较麻烦。所以一般建议是一次性分够。</td><td style="text-align:left">在线服务。一般均以UserID或者ShopID等进行hash。</td><td style="text-align:left">任意版本</td></tr><tr><td style="text-align:left">Range</td><td style="text-align:left">拿分表键按照ID范围进行路由，比如id在1-10000的在第一个表中，10001-20000的在第二个表中，依次类推。这种情况下，分表键只能是数值类型。</td><td style="text-align:left">数据量可控，可以均衡，也可以不均衡扩容比较方便，因为如果ID范围不够了，只需要调整规则，然后建好新表即可。</td><td style="text-align:left">无法解决热点问题，如果某一段数据访问QPS特别高，就会落到单表上进行操作。</td><td style="text-align:left">离线服务。</td><td style="text-align:left">2.9.4以上</td></tr><tr><td style="text-align:left">时间</td><td style="text-align:left">拿分表键按照时间范围进行路由，比如时间在1月的在第一个表中，在2月的在第二个表中，依次类推。这种情况下，分表键只能是时间类型。</td><td style="text-align:left">扩容比较方便，因为如果时间范围不够了，只需要调整规则，然后建好新表即可。</td><td style="text-align:left">数据量不可控，有可能单表数据量特别大，有可能单表数据量特别小无法解决热点问题，如果某一段数据访问QPS特别高，就会落到单表上进行操作。</td><td style="text-align:left">离线服务。比如线下运营使用的表、日志表等等</td><td style="text-align:left">2.9.4以上</td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> zebra </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zebra </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>leaf</title>
      <link href="/blog/2023/07/02/22/"/>
      <url>/blog/2023/07/02/22/</url>
      
        <content type="html"><![CDATA[<p>leaf是美团 推出的一个分布式ID生成服务，名字取自德国哲学家、数学家莱布尼茨的一句话：“There are no two identical leaves in the world.”Leaf具备高可靠、低延迟、全局唯一等特点在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识，对数据分库分表后需要有一个唯一ID来标识一条数据或消息</p><p>重写getid方法</p><p><img src="C:\Users\熊强\Pictures\学习资料\QQ截图20230703233118.png" alt="QQ截图20230703233118"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;bean id=&quot;idGen&quot; class=&quot;com.dianping.pigeon.remoting.invoker.config.spring.ReferenceBean&quot; init-method=&quot;init&quot;&gt; </span><br><span class="line">    &lt;property name=&quot;url&quot; value=&quot;com.sankuai.inf.leaf.thrift.IDGen&quot; /&gt; </span><br><span class="line">    &lt;property name=&quot;interfaceName&quot; value=&quot;com.sankuai.inf.leaf.thrift.IDGen$Iface&quot; /&gt; </span><br><span class="line">    &lt;property name=&quot;remoteAppKey&quot; value=&quot;$&#123;leaf集群appkey&#125;&quot;/&gt; </span><br><span class="line">    &lt;property name=&quot;timeout&quot; value=&quot;1000&quot; /&gt; </span><br><span class="line">    &lt;property name=&quot;callType&quot; value=&quot;sync&quot; /&gt; </span><br><span class="line">    &lt;property name=&quot;serialize&quot; value=&quot;thrift&quot; /&gt; </span><br><span class="line">&lt;/bean&gt;</span><br></pre></td></tr></table></figure><p>leaf每台服务器会缓存步长号段，如果设置步长是1000，那么每台机器都会缓存1000个ID，如下图。</p><p>步长也就是服务器每次回去加载的号段长度，并缓存到leaf服务中。（目前，leaf实现了动态调整步长的功能，会根据号段消费速度动态调整步长大小。）</p><p>所以业务得到的id号并不是严格递增的，但是不会出现重复。</p><p><img src="C:\Users\熊强\Pictures\学习资料\drawio(2" alt="drawio(2)">.svg)</p><p>假设路由采用轮询的方式，你的服务得到的id序列如下：</p><p>1，1001，2001，2，1002，2002，3，1003，2003，4，1004，2004…………</p><p>UUID </p><ul><li><strong>优点</strong>：生成速度比较快、简单易用</li><li><strong>缺点</strong>：存储消耗空间大（32 个字符串，128 位）、 不安全（基于 MAC 地址生成 UUID 的算法会造成 MAC 地址泄露)、无序（非自增）、没有具体业务含义、需要解决重复 ID 问题（当机器时间不对的情况下，可能导致会产生重复 ID）</li></ul><p>Snowflake(雪花算法)</p><p>snowflake算法是一种划分命名空间来生成ID的一种算法，这种方案把64-bit分别划分成多段，分开来标示时间戳、机器、序列号等。</p><p>第 0 位：符号位（标识正负），始终为 0，没有用，不用管。</p><p>41bit为时间戳，可以表示的时间范围为（1L&lt;&lt;41）/(1000L<em>3600</em>24*365)=69年的时间；</p><p>10bit为机器id，可用于表示1024台机器；</p><p>12bit为自增序列号，可以表示2^12个ID。</p><p>64bit的二进制转为long就是snowflake生成的Id。</p><ul><li>当通过NTP进行时钟同步时可能会出现重复ID</li></ul>]]></content>
      
      
      <categories>
          
          <category> leaf </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leaf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>elasticsearch</title>
      <link href="/blog/2023/07/02/21/"/>
      <url>/blog/2023/07/02/21/</url>
      
        <content type="html"><![CDATA[<h2 id="分片原理"><a href="#分片原理" class="headerlink" title="分片原理"></a>分片原理</h2><p>由于平台接入的数据达万级，消息队列积压严重，为提高消费端 ES 的写入，中间不单纯是一些写入，做各种各样的处理，插入到第三方表，整体流程耗时非常严重，使用方不能及时搜索到商品的信息，第一期的话是全部改成批量操作，充分利用系统资源，发现这些指标还是上不去，像一些非核心的逻辑，要求不是那么实时，那我就开一个异步线程来异步化，迭代到最后面，攒批多线程插入，就先拉一批数据到全局队列中去，再开一个线程池，启动线程池，对数据进行分片后多线程批次插入，ES 提供了 Bulk API 支持批量操作，当我们有大量的写任务时，可以使用 Bulk 来进行批量写入。</p><p>当前一个数据通过路由计算公式得到的值是 shard=hash(routing)%4=0，则具体流程如下：</p><p>（1）数据写请求发送到 node1 节点，通过路由计算得到值为1，那么对应的数据会应该在主分片S1上。<br>（2）node1节点将请求转发到 S1 主分片所在的节点node2，node2 接受请求并写入到磁盘。<br>（3）并发将数据复制到三个副本分片R1上，其中通过乐观并发控制数据的冲突。一旦所有的副本分片都报告成功，则节点 node2将向node1节点报告成功，然后node1节点向客户端报告成功。</p><p>这种模式下，只要有副本在，写入延时最小也是两次单分片的写入耗时总和，效率会较低，但是这样的好处也很明显，避免写入后单个机器硬件故障导致数据丢失，在数据完整性和性能方面，一般都是优先选择数据，除非一些允许丢数据的特殊场景。</p><h2 id="主从"><a href="#主从" class="headerlink" title="主从"></a>主从</h2><p>一个ES集群可以有多个节点构成，一个节点就是一个ES服务实例，ES集群中节点的角色</p><p><strong>候选主节点：</strong>只有是候选主节点才可以参与选举投票，也只有候选主节点可以被选举为主节点。</p><p><strong>主节点：</strong>负责索引的添加、删除，跟踪哪些节点是群集的一部分，对分片进行分配、收集集群中各节点的状态等，稳定的主节点对集群的健康是非常重要。</p><p><strong>数据节点：</strong>负责对数据的增、删、改、查、聚合等操作，数据的查询和存储都是由数据节点负责，对机器的CPU，IO以及内存的要求比较高，一般选择高配置的机器作为数据节点。</p><p>节点就可以加入集群，那么ES是如何做到这一点的呢？</p><p>这里就要讲一讲ES特殊的发现机制ZenDiscovery。</p><p>ZenDiscovery是ES的内置发现机制，提供单播和多播两种发现方式，主要职责是集群中节点的发现以及选举Master节点。</p><p><strong>多播也叫组播</strong>，指一个节点可以向多台机器发送请求。生产环境中ES不建议使用这种方式，对于一个大规模的集群，组播会产生大量不必要的通信。</p><p><strong>单播</strong>，当一个节点加入一个现有集群，或者组建一个新的集群时，请求发送到一台机器。当一个节点联系到单播列表中的成员时，它就会得到整个集群所有节点的状态，然后它会联系Master节点，并加入集群。</p><p>只有在同一台机器上运行的节点才会自动组成集群。ES 默认被配置为使用单播发现，单播列表不需要包含集群中的所有节点，它只是需要足够的节点，当一个新节点联系上其中一个并且通信就可以了</p><h2 id="脑裂"><a href="#脑裂" class="headerlink" title="脑裂"></a><strong>脑裂</strong></h2><p>提到分布式系统选主，不可避免的会提到脑裂这样一个现象，什么是脑裂呢？如果集群中选举出多个Master节点，使得数据更新时出现不一致，这种现象称之为脑裂。</p><p>简而言之集群中不同的节点对于 Master的选择出现了分歧，出现了多个Master竞争。</p><p>一般而言脑裂问题可能有以下几个<strong>原因</strong>造成：</p><ul><li><strong>网络问题：</strong>集群间的网络延迟导致一些节点访问不到Master，认为Master 挂掉了，而master其实并没有宕机，而选举出了新的Master，并对Master上的分片和副本标红，分配新的主分片。</li><li><strong>节点负载：</strong>主节点的角色既为Master又为Data，访问量较大时可能会导致 ES 停止响应（假死状态）造成大面积延迟，此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点。</li><li><strong>内存回收：</strong>主节点的角色既为Master又为Data，当Data节点上的ES进程占用的内存较大，引发JVM的大规模内存回收，造成ES进程失去响应。</li></ul><p>如何避免脑裂：我们可以基于上述原因，做出优化措施：</p><ul><li>适当调大响应超时时间，减少误判。通过参数 discovery.zen.ping_timeout 设置节点ping超时时间，默认为 3s，可以适当调大。</li><li>选举触发，我们需要在候选节点的配置文件中设置参数 discovery.zen.munimum_master_nodes 的值。这个参数表示在选举主节点时需要参与选举的候选主节点的节点数，默认值是 1，官方建议取值(master_eligibel_nodes/2)+1，其中 master_eligibel_nodes 为候选主节点的个数。这样做既能防止脑裂现象的发生，也能最大限度地提升集群的高可用性，因为只要不少于 discovery.zen.munimum_master_nodes 个候选节点存活，选举工作就能正常进行。当小于这个值的时候，无法触发选举行为，集群无法使用，不会造成分片混乱的情况。</li><li>角色分离，即是上面我们提到的候选主节点和数据节点进行角色分离，这样可以减轻主节点的负担，防止主节点的假死状态发生，减少对主节点宕机的误判</li></ul><p><img src="C:\Users\熊强\Pictures\学习资料\image-20230822105433029.png" alt="image-20230822105433029"></p><p><img src="C:\Users\熊强\Pictures\学习资料\image-20230822105452064.png" alt="image-20230822105452064"></p><p><img src="C:\Users\熊强\Pictures\学习资料\image-20230822105547197.png" alt="image-20230822105547197"></p>]]></content>
      
      
      <categories>
          
          <category> elasticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AIGC</title>
      <link href="/blog/2023/06/23/20/"/>
      <url>/blog/2023/06/23/20/</url>
      
        <content type="html"><![CDATA[<p>++</p><p>+</p><h2 id="使用AIGC工具的优点"><a href="#使用AIGC工具的优点" class="headerlink" title="使用AIGC工具的优点"></a>使用AIGC工具的优点</h2><h3 id="（1）提高工作效率"><a href="#（1）提高工作效率" class="headerlink" title="（1）提高工作效率"></a>（1）提高工作效率</h3><p>大型语言和图像AI模型可用于自动生成内容，例如文章、博客或社交媒体帖子。对于定期创建内容的企业和专业人士来说，是非常节省时间的工具，将成本显著降低效率，效率提高。</p><h3 id="（2）提高内容质量"><a href="#（2）提高内容质量" class="headerlink" title="（2）提高内容质量"></a>（2）提高内容质量</h3><p>AIGC生成的内容可能比人类创建的内容质量更高，因为AI模型能够从大量数据中学习并生成一些人类认知不到的一些内容。例如DALL · E 2 和 Google 的 Imagen 都可以通过文字来要求AI画出描述的具体内容，并且效果已经接近中等画师的水平。</p><h3 id="（3）增加内容多样性"><a href="#（3）增加内容多样性" class="headerlink" title="（3）增加内容多样性"></a>（3）增加内容多样性</h3><p>首先，目前的AIGC多模态模型可以生成多种类型的内容，包括文本、图像和音视频等等；其次，AIGC生成的内容可以进行定制化、风格化迁移。</p><h2 id="文本生成AI（搜索、文案、写作）"><a href="#文本生成AI（搜索、文案、写作）" class="headerlink" title="文本生成AI（搜索、文案、写作）"></a>文本生成AI（搜索、文案、写作）</h2><p>以结构性新闻撰写、内容续写、诗词创作等细分功能为代表，基于NLP技术的文本生成可以算作是AIGC中发展最早的一部分技术，也已经在新闻报道、对话机器人等应用场景中大范围商业落地。</p><p>自然语言处理算法（NLP）目前以<strong>Transformer架构</strong>为核心进行迭代，它是一种采用自注意力机制的模型，能够根据输入数据各部分的重要性而分配不同的权重，非常适用于文本处理的词法分析和语义分析。比如谷歌的BERT模型和openAI的GPT系列模型都是基于Transformer架构进行实现的。</p><p><strong>ChatGPT</strong>, 文心一言</p><h2 id="图像-视频生成AI"><a href="#图像-视频生成AI" class="headerlink" title="图像/视频生成AI"></a>图像/视频生成AI</h2><p>最早提出的模型是<strong>生成对抗网络</strong>（Generative Adversarial Nets，简称GAN），由生成器和判别器两部分组成，生成器将抓取数据、产生新的生成数据，并将其混入原始数据中送交判别器区分。这一过程将反复进行，直到判别器无法以超过50%的准确度分辨出真实样本。2022年，<strong>Diffusion model</strong>成为图像生成领域的重要发现，Diffusion是指扩散模型。最初受到热力学概念的启发，扩散模型通过增加噪声破坏训练数据来学习，然后找出如何逆转这种噪声过程以恢复原始图像。一旦经过训练，扩散模型就可以应用这些去噪方法从随机输入中合成新颖的“干净”数据。相比GAN方法，在所需数据更少的背景下，Diffusion Model的图像生成效果有明显提升。</p><p>Mid-journey,阿里鹿班</p><p><strong>美团在aigc上的实践</strong>：FRIDAY 大模型平台是由美团平台提供的端到端大模型应用服务平台，我们基于国外 OpenAI / Anthropic / Google,  国内 MiniMax / 讯飞等开放的模型（GPT4、GPT-3.5-turbo、Claude、PaLM2、星火等）、自研/采购大模型（ChatGLM 130B等）、开源基础模型对公司内各个团队提供稳定、便捷、灵活的大模型一站式解决方案，</p><p>基于FRIDAY的小美智能助理是一款人工智能应用开发平台，与ChatGPT类似，它基于自然语言处理技术，能够让用户与机器进行自然、流畅的交流。这个平台支持多种类型的对话应用，如客户服务、问答、虚拟助手等等。MCopilot是一个AI编程辅助工具，在一些情况下，只需要注释就可以提示代码</p>]]></content>
      
      
      <categories>
          
          <category> AIGC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AIGC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mafka</title>
      <link href="/blog/2023/06/22/19/"/>
      <url>/blog/2023/06/22/19/</url>
      
        <content type="html"><![CDATA[<p>Mafka是美团自研的一个高可用、可拓展、高性能的分布式消息队列服务,底层基于Apache Kafka，广泛用于消息异步处理、应用解耦、流量削峰、发布/订阅模型等场景。Mafka为研发工程师提供全托管的消息队列服务，用户只需专注于业务开发无需部署运维。</p><h2 id="用户场景"><a href="#用户场景" class="headerlink" title="用户场景"></a>用户场景</h2><ol><li><p>异步处理模式</p><ol><li>消息发送者 可以发送一个消息而无须等待消费者响应。消息发送者将消息发送到一条 虚拟的通道（主题 或 队列）上，消息接收者则订阅或是监听该通道。一条信息可能最终转发给 一个或多个 消息接收者，这些接收者都无需对消息发送者做出同步回应，整个过程都是异步的。</li></ol></li><li><p>应用系统之间的解耦合</p><ol><li>发送者和接受者不必了解对方、只需要确认消息，比如发送和接收者可以是不同的系统，不同的语言编写的，地理上可以不在同一个地域</li><li>发送者和接受者不必同时在线</li></ol></li><li><p>流量削峰</p><ol><li>当在线api接口在应对高峰流量时，比如“秒杀”，“流量激增”时，如果接口处理能力有限，可以先将无法及时处理的请求发送给消息队列，后台处理，防止流量过大将api接口服务打死。</li><li>“秒杀”场景需要下游消费方的消费能力达到最大，业务方可以使用push类型消费组进行消费</li></ol></li><li><p>发布/订阅模型(Pub/Sub)</p><ol><li>一条消息，可以广播给任意多个收听方</li></ol></li><li><p>将Mafka作为临时存储</p><ol><li><p>在将消息发给Mafka后，设置无限期过期时间，需要的时候从头开始消费，获取存储。比如内存式cache的构建，生产cache数据的时候，可以同时把数据发给Mafka一份，这样在cache机器重启后直接从Mafka读取数据，构建cache，这样就省去了构建cache时重复的计算逻辑。</p><h2 id="定制内容"><a href="#定制内容" class="headerlink" title="定制内容"></a>定制内容</h2></li></ol></li></ol><div class="table-container"><table><thead><tr><th style="text-align:left">特性</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">消息回放</td><td style="text-align:left">Mafka 支持最长 7 天的消息回溯，也就是说，可以实现多次重复消费最长 7 天以内的消息(默认 7 天，根据业务需求可以调节)</td></tr><tr><td style="text-align:left">中心化调度</td><td style="text-align:left">基于机房粒度的生产者和消费者调度，让业务达到同机房优先生产或消费，同地域优先生产或消费。</td></tr><tr><td style="text-align:left">延时消息</td><td style="text-align:left">Mafka 支持最短 5s，最长 30 天的延迟时间范围，生产者将延时消息先发送给 Mafka，当消息到期后，Mafka 再将消息发送给消费者。</td></tr><tr><td style="text-align:left">Push消费</td><td style="text-align:left">消费者通过 PushServer 来消费消息，对 Mafka 的 Partition 透明，消费者数量不再受制于 Partition 数量。</td></tr></tbody></table></div><h2 id="消息回放原理介绍"><a href="#消息回放原理介绍" class="headerlink" title="消息回放原理介绍"></a>消息回放原理介绍</h2><p>broker中的消息在磁盘中是一个appendLog文件，顺序追加到日志文件尾部，每条消息都有一个唯一标识——offset。消费者通过offset位置决定消费消息的位置。mafka提供通过重新设置offset来重新消费消息或者跳过某些消息的功能。</p><ol><li>数据修复和恢复：当生产环境出现数据错误或数据丢失时，可以使用mafka消息回放工具，将历史数据重新发送到生产环境中，以修复和恢复数据。</li><li>测试和调试：在开发和测试过程中，可以使用mafka消息回放工具，将历史数据重新发送到测试环境中，以测试和调试应用程序的正确性和性能。</li><li>数据分析和统计：在数据分析和统计过程中，可以使用mafka消息回放工具，将历史数据重新发送到数据分析和统计系统中，以进行数据分析和统计。</li><li>数据备份和迁移：在数据备份和迁移过程中，可以使用mafka消息回放工具，将历史数据重新发送到备份和迁移系统中，以保证数据的完整性和一致性。</li></ol><p>Push消费原理介绍</p><p>（1）由PushServer内部的消费者客户端（Mafka客户端）从Broker集群拉取消息，并投递到内存队列中（内存队列所有分区共享，队列大小为100）。</p><p>（2）PushTask任务从内存队列中获取消息，并逐一推送给链接到当前节点的所有客户端。</p><p>（3）TimeOutCheckTask负责检查所有已经推送给客户端的消息是否响应超时（默认响应时间为100s），如果客户端响应超时，则将超时消息投递到超时队列中。</p><p>（4）PushTask获取新的消息进行推送时，优先从超时队列中拉取消息进行投递。</p><p>延时消息原理介绍</p><h2 id="消费组粒度延迟"><a href="#消费组粒度延迟" class="headerlink" title="消费组粒度延迟"></a>消费组粒度延迟</h2><p>说明：在消费组配置项中修改，是消费组粒度的延迟，每个消费组单独做设置即可（这里需要注意，具体泳道，SET和主干环境，需要具体到各个环境的消费组下修改配置才能生效，不能只修改主干消费组配置），使用这个消费组的所有消息都延迟的时间相同，该延迟时间没有限制，可以自定义设置，以秒为单位。</p><ul><li><p>消费组延迟生效在消费端，大概原理可以理解为客户端收到消息之后延迟一定时间之后再调用业务消费逻辑进行消费。</p></li><li><p>代码不需要做任何变更，只需要在消费组配置页面修改如下标红参数即可，业务侧在有消费组写权限的情况下可以自己修改该配置，申请人都有该项修改权限，修改完成后，接入就会生效。</p></li><li>代码接入参考普通的mafka生产端和消费端接入即可，可以参考管理平台的Demo代码示例。</li><li>该延时方式适合短时间的延时，服务端保存消息单分区最多10G，如果消息流量大，<strong>延时时间长可能导致尚未被消费的消息被服务端清理掉造成消息丢失。</strong></li></ul><h2 id="消息粒度延迟"><a href="#消息粒度延迟" class="headerlink" title="消息粒度延迟"></a>消息粒度延迟</h2><p>延时消息接入分两步：</p><ol><li>MQ平台主题配置页面修改delay.enable=true</li><li>代码中创建producer使用 MafkaClient.buildDelayProduceFactory(或者通过bean方式创建两种方式都要!!!!!必须要改代码)</li><li>发送消息使用带delay的发送方法，比如sendDelayMessage、sendAsyncDelayMessage</li></ol><p>消息粒度延迟的原理大概是客户端在发送消息之后，不会马上发送到broker,而是先把消息暂存到cellar中，等延时时间到达才正式发送消息到broker。每条消息的延迟时间可以不同，通过代码控制。</p><h2 id="消息积压"><a href="#消息积压" class="headerlink" title="消息积压"></a>消息积压</h2><p>所有积压问题都可以理解成是消费能力不足的问题,导致消费能力不足原因有很多，</p><p>1.生产量突增</p><p>联系管理员扩容partition</p><p>2.消费组停用</p><p>可以在mafka的管理平台的消费组页面,查看有没有启动消费者或者启动消费者失败，请查看日志中是否有异常：</p><p>3.消费慢了，增加消费能力</p><p>优化消费逻辑——降低消费逻辑处理耗时（最主要的方式!!!）有的业务场景消费逻辑比较耗时，消费耗时就导致消费消息的qps不高，消费能力不高。这就需要业务方优化消费逻辑代码，降低处理耗时，从而提升处理能力。</p><p>增加单机消费线程数（推荐!!!）——提升单机消费能力，增加单partiton并行消费线程数目（<strong>这种方式不保证消费顺序！！！</strong>）</p><p> 调整分配模式——让消费者负载更均衡（推荐!!!）查看消费组配置修改页面，如果partition.assign.mode=默认分配模式，并且有较多的消费者没有抢占到partition,可以将该模式设置为消费者均衡模式，该模式能够最大化利用消费者来提升消费能力。</p><p>调整消费策略——减少跨地域调用的网络时延在消费组页面，查看消费状态信息，是否出现跨地域消费情况，即是否出现上海机器在消费北京集群的情况（或者北京机器在消费上海集群的情况），跨地域消费会增加网络耗时，导致消费时延较高，消费速率慢，建议调整成同机房优先或者同地域优先。</p><p>单机消费能力达到瓶颈（可以通过机器的CPU、内存、网卡的变化来判断）后，可以增加消费者机器数目；优先提高单机的处理能力</p><h2 id="丢消息问题"><a href="#丢消息问题" class="headerlink" title="丢消息问题"></a>丢消息问题</h2><p>主题ack配置确认，首先确定主题的ack配置，如果request.required.acks 不是 默认值 -1，消息可能在发送过程中丢失。 request.required.acks=-1，消息会被同步到多个副本成功后再给生产者返回成功，只要多个副本不同时故障，就不会有消息丢失。</p><p>通过消息轨迹进行消息的查询，按照对应的时间可以查询到对应的消息。如果此处有，那么消息就已经保存到了broker中，不存在丢消息的情况，请仔细检查消费者端的逻辑。</p><p>如果消息丢失，那么建议看一下代码中，是否在别的应用中用同一个消费组内启用了多个消费者实例，导致消息被另外一个消费组消费。</p><p>业务发现丢消息并且可能存在当前topic consumer无法消费到消息的情况。这个可能是开启了环境隔离，导致消息被生产到环境隔离的topic中，所以导致当前的topic没有消息(疑似丢消息)。可以上管理平台看一下是否开启了环境隔离，并且可以检查一下对应的消费日志。</p><p>积压过多导致被系统删除，Mafka系统中保存的消息是有限的，一旦超过限制就会把最老的消息清理掉，维持保存的消息总量不超限。一旦消费积压过多，可能出现还未消费的消息被服务端清理的情况，此时消费者一般会选择从该分区的最新位置开始消费消息，确定是否是该场景：MQ管理平台的消息积压分布有一个突降</p><h2 id="消息重复消费"><a href="#消息重复消费" class="headerlink" title="消息重复消费"></a>消息重复消费</h2><p>1.业务方重复生产</p><p>由于业务方的原因，可能对同一份消息内容发送了多次，造成该消息在Mafka系统内重复。在该场景下，重复消息的msgId、offset(cluster、partition)信息是不同的。</p><p>2.Mafka重复生产</p><p>mafka客户端在发送消息时，会有内部重试，默认一条消息发送失败会自动重试3次，如果所有重试都失败，会给用户返回【发送失败】的结果，但是该消息仍然可能存在于mafka系统中。在该场景下，重复消息的生产方都是同一台机器，并且发送间隔时间较短(30s内)，重复消息的msgId相同、offset(cluster、partition)信息是不同的。</p><p>3.消费失败重复消费</p><p>消费状态码在RECONSUME_LATER(消费重试)、CONSUME_FAILURE(消费失败)两种情况下，会在客户端进程内进行多次消费重试。再该场景下，重复消息的msgId、offset(cluster、partition)信息是相同的，消费的机器是相同的机器</p><p>4.分区变动重复消费</p><p>在客户端实例变化、分区扩容、集群切换等场景会涉及到分区重分配，由于新老客户端感知分配结果不及时，可能出现两台机器短时间消费同一个分区的场景，造成重复消费。再该场景下，重复消息的msgId、offset(cluster、partition)信息是相同的，消费的机器是两台不同的机器。</p><h2 id="顺序消费"><a href="#顺序消费" class="headerlink" title="顺序消费"></a>顺序消费</h2><ol><li>发送消息可以通过携带key决定partition(相同的可以落到同一个partition上)，</li><li>不能开并发消费：不能通过调整单partition并行消费线程个数(consumer.parallel.num)来增加消费能力，多线程并发无法保证顺序</li><li>不能使用push消费：Push消费类型无法保证消费顺序</li></ol>]]></content>
      
      
      <categories>
          
          <category> mafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>需求集成LightMerge能力接入</title>
      <link href="/blog/2023/06/22/18/"/>
      <url>/blog/2023/06/22/18/</url>
      
        <content type="html"><![CDATA[<h3 id="LightMerge是什么？"><a href="#LightMerge是什么？" class="headerlink" title="LightMerge是什么？"></a><strong>LightMerge是什么？</strong></h3><p>LightMerge即轻量级Merge，目标是将多个分支快速合并到一个分支，合并操作相较 PR 来说更轻量级(不提供 diff 查看，评审，卡点等功能)，一般用于线下测试时快速生成集成分支。版本发版分支上线的内容由多个RD在多个分支开发实现，在上线前需要将多个开发分支的内容合并进集成分支进行发版。为此引入Code平台提供的git能力，</p><h3 id="如何使用LightMerge？"><a href="#如何使用LightMerge？" class="headerlink" title="如何使用LightMerge？"></a>如何使用LightMerge？</h3><p>拥有<strong>仓库写权限或者管理员权限</strong>的用户可以使用LightMerge功能。</p><ul><li><p>通过新建LightMerge可以新建一个多分支的合并，将多个源分支合并到目标分支中，重要的分支（如Master分支）最好设置为LightMerge保护分支，防止在整个LightMerge的过程中污染了重要分支代码</p></li><li><p>在源分支的添加中，最新加入的分支在最前面，因为LightMerge会按页面展示的分支顺序执行，保障修复LightMerge中发生冲突的分支添加后可最先被合并</p></li><li><p>通过Edit按钮可以修改基础分支、增加或删除源分支</p></li><li><p>通过Check按钮可以校验分支中是否冲突，如果有冲突，请按照对应的冲突信息解决</p></li><li><p>通过Refresh and Push按钮可以进行分支的合并（每一次合并前请先点击Check按钮确认是否有冲突），合并会修改目标分支代码，请一定注意</p></li><li><p>通过Delete按钮可以将该LightMerge删除</p></li></ul><p>在源分支上解决冲突，在本地的 source2 分支上，通过复制 lightmerge 的 merge 流程，复现出冲突，然后在 source2  分支上解决冲突后提交，并重新执行 lightmerge， 破坏了源分支的独立性，导致用于解决冲突的源分支提前 merge 了其他源分支(为了解决冲突)</p><p>sop:</p><p>git checkout source2</p><p>git fetch</p><p>git merge origin/master</p><p>git merge origin/source1</p><p>自行解决冲突</p><p>git push origin source2</p><p>重新执行 lightmerge</p><p><img src="C:\Users\熊强\Pictures\学习资料\drawio.svg" alt="drawio"></p>]]></content>
      
      
      <categories>
          
          <category> 需求集成LightMerge能力接入 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 需求集成LightMerge能力接入 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hashmap</title>
      <link href="/blog/2023/05/17/16/"/>
      <url>/blog/2023/05/17/16/</url>
      
        <content type="html"><![CDATA[<p><img src="C:\Users\熊强\Pictures\学习资料\20230517231103.png" alt="img"></p><h2 id="为什么都要扩展为原来的2倍"><a href="#为什么都要扩展为原来的2倍" class="headerlink" title="为什么都要扩展为原来的2倍"></a>为什么都要扩展为原来的2倍</h2><p>这是因为，将数组容量扩展为原来的两倍，可以在保证空间利用率的同时，最大限度地减少哈希冲突的发生。具体地说，如果将数组容量扩展为原来的 k 倍，虽然可以进一步降低哈希冲突的概率，但也会造成空间浪费；而如果将数组容量扩展为原来的 1.5 倍，虽然可以减少空间浪费，但也会增加哈希冲突的概率。因此，将数组容量扩展为原来的两倍，可以在空间利用率和哈希冲突之间取得一个较好的平衡。<strong>hash % length == hash &amp; (length - 1)这个关系只有在length等于二的幂次方时成立，位运算能比%高效得多</strong></p><h2 id="扩容因子为什么是-0-75"><a href="#扩容因子为什么是-0-75" class="headerlink" title="扩容因子为什么是 0.75"></a>扩容因子为什么是 0.75</h2><p>而<code>HashMap</code>中加载因子为0.75，是考虑到了性能和容量的平衡。</p><p>由加载因子的定义，可以知道它的取值范围是(0, 1]。</p><ul><li>如果加载因子过小，那么扩容门槛低，扩容频繁，这虽然能使元素存储得更稀疏，有效避免了哈希冲突发生，同时操作性能较高，但是会占用更多的空间。</li><li>如果加载因子过大，那么扩容门槛高，扩容不频繁，虽然占用的空间降低了，但是这会导致元素存储密集，发生哈希冲突的概率大大提高，从而导致存储元素的数据结构更加复杂（用于解决哈希冲突），最终导致操作性能降低。</li><li>还有一个因素是为了提升扩容效率。因为<code>HashMap</code>的容量（<code>size</code>属性，构造函数中的<code>initialCapacity</code>变量）有一个要求：它一定是2的幂。所以加载因子选择了0.75就可以保证它与容量的乘积为整数。</li></ul><p>在负载因子0.75（HashMap默认）的情况下，单个hash槽内元素个数为8的概率小于百万分之一，将7作为一个分水岭，等于7时不做转换，大于等于8才转红黑树，小于等于6才转链表。链表中元素个数为8时的概率已经非常小，再多的就更少了，所以原作者在选择链表元素个数时选择了8，是根据概率统计而选择的。</p><p><img src="C:\Users\熊强\AppData\Roaming\Typora\typora-user-images\image-20230821001313005.png" alt="image-20230821001313005" style="zoom: 33%;" /></p>]]></content>
      
      
      <categories>
          
          <category> hashmap </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hashmap </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MD5加密原理</title>
      <link href="/blog/2023/05/17/15/"/>
      <url>/blog/2023/05/17/15/</url>
      
        <content type="html"><![CDATA[<p>MD5算法是Hash算法的一种，叫做讯息摘要演算法。在MD5算法中，这个摘要是指将任意数据映射成一个128位长的摘要信息。并且其是不可逆的，即从摘要信息无法反向推演中原文，在演算过程中，原文的内容也是有丢失的。</p><p> MD5算法大致分为4步完成：</p><p>第1步：进行数据填充整理</p><p>   这一步是对要加密的数据进行填充和整理，将要加密的二进制数据对512取模，得到的结果如果不够448位，则进行补足，补足的方式是第1位填充1，后面全部填充0。</p><p>第2步：记录数据长度</p><p>   经过第一步整理完成后的数据的位数可以表示为N<em>512+448，再向其后追加64位用来存储数据的长度，比如数据的长度为16字节，则用10000来填充后64位。这一步做完后，数据的位数将变成(N+1)</em>512。</p><p>第3步：以标准的幻数作为输入</p><p>  MD5的实现需要每512个字节进行一次处理，后一次处理的输入为前一次处理的输出，因此，在循环处理开始之前，需要拿4个标准数作为输入</p><p>第4步：进行N轮循环处理，将最后的结果输出</p><p>  这一步重要的是每一轮的处理算法，每一轮处理也要循环64次，这64次循环被分为4各组，每16次循环为一组，每组循环使用不同的逻辑处理函数，处理完成后，将输出作为输入进入下一轮循环</p>]]></content>
      
      
      <categories>
          
          <category> MD5 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MD5 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>快手原理</title>
      <link href="/blog/2023/05/17/14/"/>
      <url>/blog/2023/05/17/14/</url>
      
        <content type="html"><![CDATA[<p>kconf</p>]]></content>
      
      
      <categories>
          
          <category> 快手原理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 快手原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker原理</title>
      <link href="/blog/2023/04/19/12/"/>
      <url>/blog/2023/04/19/12/</url>
      
        <content type="html"><![CDATA[<p>docker run命令的作用是在一个全新的Docker容器内部运行一条指令。Docker在执行这条命令的时候，所做工作可以分为两部分：第一，创建Docker容器所需的rootfs；第二，创建容器的网络等运行环境，并真正运行用户指令。因此，在整个执行流程中，Docker Client给Docker Server发送了两次HTTP请求，第二次请求的发起取决于第一次请求的返回状态。Docker run命令执行流程如图5.2。</p><p><img src="C:\Users\熊强\Pictures\学习资料\2015-11-12_56443b08b556f.jpg" alt="img" style="zoom:33%;" /></p><p>图5.2 docker run命令执行流程示意图</p><p>如图，图中标记的红色箭头表示docker run命令在发起后，Docker所做的一系列运行。以下逐一分析这些步骤。</p><p>(1) Docker Client接受docker run命令，解析完请求以及收集完请求参数之后，发送一个HTTP请求给Docker Server，HTTP请求方法为POST，请求URL为”/containers/create? “+”xxx”；</p><p>(2) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler；</p><p>(3) mux.Router将请求路由分发至相应的handler，具体为PostContainersCreate；</p><p>(4) 在PostImageCreate这个handler之中，一个名为”create”的job被创建，并开始让该job运行；</p><p>(5) 名为”create”的job在运行过程中，执行Container.Create操作，该操作需要获取容器镜像来为Docker容器创建rootfs，即调用graphdriver；</p><p>(6) graphdriver从Graph中获取创建Docker容器rootfs所需要的所有的镜像；</p><p>(7) graphdriver将rootfs所有镜像，加载安装至Docker容器指定的文件目录下；</p><p>(8) 若以上操作全部正常执行，没有返回错误或异常，则Docker Client收到Docker Server返回状态之后，发起第二次HTTP请求。请求方法为”POST”，请求URL为”/containers/“+container_ID+”/start”；</p><p>(9) Docker Server接受以上HTTP请求，并交给mux.Router，mux.Router通过URL以及请求方法来确定执行该请求的具体handler；</p><p>(10)mux.Router将请求路由分发至相应的handler，具体为PostContainersStart；</p><p>(11)在PostContainersStart这个handler之中，名为”start”的job被创建，并开始执行；</p><p>(12)名为”start”的job执行完初步的配置工作后，开始配置与创建网络环境，调用networkdriver；</p><p>(13)networkdriver需要为指定的Docker容器创建网络接口设备，并为其分配IP，port，以及设置防火墙规则，相应的操作转交至libcontainer中的netlink包来完成；</p><p>(14)netlink完成Docker容器的网络环境配置与创建；</p><p>(15)返回至名为”start”的job，执行完一些辅助性操作后，job开始执行用户指令，调用execdriver；</p><p>(16)execdriver被调用，初始化Docker容器内部的运行环境，如命名空间，资源控制与隔离，以及用户命令的执行，相应的操作转交至libcontainer来完成；</p><p>(17)libcontainer被调用，完成Docker容器内部的运行环境初始化，并最终执行用户要求启动的命令。</p><h3 id="7-1-虚拟化技术"><a href="#7-1-虚拟化技术" class="headerlink" title="7.1 虚拟化技术"></a>7.1 虚拟化技术</h3><p>首先，Docker <strong>容器虚拟化</strong>技术为基础的软件，那么什么是虚拟化技术呢？</p><p>简单点来说，虚拟化技术可以这样定义：</p><blockquote><p>虚拟化技术是一种资源管理技术，是将计算机的各种<a href="https://zh.wikipedia.org/wiki/資源_(計算機科學" title="实体资源">实体资源</a>)（<a href="https://zh.wikipedia.org/wiki/CPU">CPUopen in new window</a>、<a href="https://zh.wikipedia.org/wiki/内存">内存open in new window</a>、<a href="https://zh.wikipedia.org/wiki/磁盘空间">磁盘空间open in new window</a>、<a href="https://zh.wikipedia.org/wiki/網路適配器">网络适配器open in new window</a>等），予以抽象、转换后呈现出来并可供分割、组合为一个或多个电脑配置环境。由此，打破实体结构间的不可切割的障碍，使用户可以比原本的配置更好的方式来应用这些电脑硬件资源。这些资源的新虚拟部分是不受现有资源的架设方式，地域或物理配置所限制。一般所指的虚拟化资源包括计算能力和数据存储。</p></blockquote><h3 id="7-2-Docker-基于-LXC-虚拟容器技术"><a href="#7-2-Docker-基于-LXC-虚拟容器技术" class="headerlink" title="# 7.2 Docker 基于 LXC 虚拟容器技术"></a><a href="#_7-2-docker-基于-lxc-虚拟容器技术">#</a> 7.2 Docker 基于 LXC 虚拟容器技术</h3><p>Docker 技术是基于 LXC（Linux container- Linux 容器）虚拟容器技术的。</p><blockquote><p>LXC，其名称来自 Linux 软件容器（Linux Containers）的缩写，一种操作系统层虚拟化（Operating system–level virtualization）技术，为 Linux 内核容器功能的一个用户空间接口。它将应用软件系统打包成一个软件容器（Container），内含应用软件本身的代码，以及所需要的操作系统核心和库。通过统一的名字空间和共用 API 来分配不同软件容器的可用硬件资源，创造出应用程序的独立沙箱运行环境，使得 Linux 用户可以容易的创建和管理系统或应用容器。</p></blockquote><p>LXC 技术主要是借助 Linux 内核中提供的 CGroup 功能和 namespace 来实现的，通过 LXC 可以为软件提供一个独立的操作系统运行环境。</p><p><strong>cgroup 和 namespace 介绍：</strong></p><ul><li><p><strong>namespace 是 Linux 内核用来隔离内核资源的方式。</strong> 通过 namespace 可以让一些进程只能看到与自己相关的一部分资源，而另外一些进程也只能看到与它们自己相关的资源，这两拨进程根本就感觉不到对方的存在。具体的实现方式是把一个或多个进程的相关资源指定在同一个 namespace 中。Linux namespaces 是对全局系统资源的一种封装隔离，使得处于不同 namespace 的进程拥有独立的全局系统资源，改变一个 namespace 中的系统资源只会影响当前 namespace 里的进程，对其他 namespace 中的进程没有影响。</p><p>（以上关于 namespace 介绍内容来自<a href="https://www.cnblogs.com/sparkdev/p/9365405.html">https://www.cnblogs.com/sparkdev/p/9365405.html</a> ，更多关于 namespace 的呢内容可以查看这篇文章 ）。</p></li><li><p><strong>CGroup 是 Control Groups 的缩写，是 Linux 内核提供的一种可以限制、记录、隔离进程组 (process groups) 所使用的物力资源 (如 cpu memory i/o 等等) 的机制。</strong></p></li></ul><hr>]]></content>
      
      
      <categories>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes原理</title>
      <link href="/blog/2023/04/18/11/"/>
      <url>/blog/2023/04/18/11/</url>
      
        <content type="html"><![CDATA[<p>Kubernetes 中的绝大部分概念都抽象成 Kubernetes 管理的一种资源对象，下面我们一起复习一下我们上节课遇到的一些资源对象：</p><ul><li><p>Master：Master 节点是 Kubernetes 集群的控制节点，负责整个集群的管理和控制。Master 节点上包含以下组件：</p></li><li><p>kube-apiserver：集群控制的入口，提供 HTTP REST 服务</p></li><li><p>kube-controller-manager：Kubernetes 集群中所有资源对象的自动化控制中心</p></li><li><p>kube-scheduler：负责 Pod 的调度</p></li><li><p>Node：Node 节点是 Kubernetes 集群中的工作节点，Node 上的工作负载由 Master 节点分配，工作负载主要是运行容器应用。Node 节点上包含以下组件：</p><ul><li>kubelet：负责 Pod 的创建、启动、监控、重启、销毁等工作，同时与 Master 节点协作，实现集群管理的基本功能。</li><li>kube-proxy：实现 Kubernetes Service 的通信和负载均衡</li><li>运行容器化(Pod)应用</li></ul></li><li><p>Pod: Pod 是 Kubernetes 最基本的部署调度单元。每个 Pod 可以由一个或多个业务容器和一个根容器(Pause 容器)组成。一个 Pod 表示某个应用的一个实例</p></li><li><p>ReplicaSet：是 Pod 副本的抽象，用于解决 Pod 的扩容和伸缩</p></li><li><p>Deployment：Deployment 表示部署，在内部使用ReplicaSet 来实现。可以通过 Deployment 来生成相应的 ReplicaSet 完成 Pod 副本的创建</p></li><li><p>Service：Service 是 Kubernetes 最重要的资源对象。Kubernetes 中的 Service 对象可以对应微服务架构中的微服务。Service 定义了服务的访问入口，服务的调用者通过这个地址访问 Service 后端的 Pod 副本实例。Service 通过 Label Selector 同后端的 Pod 副本建立关系，Deployment 保证后端Pod 副本的数量，也就是保证服务的伸缩性。</p><p><img src="C:\Users\熊强\Pictures\学习资料\k8s-basic.png" alt="k8s basic"></p><p>Kubernetes 主要由以下几个核心组件组成:</p><ul><li>etcd 保存了整个集群的状态，就是一个数据库；</li><li>apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制；</li><li>controller manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；</li><li>scheduler 负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上；</li><li>kubelet 负责维护容器的生命周期，同时也负责 Volume（CSI）和网络（CNI）的管理；</li><li>Container runtime 负责镜像管理以及 Pod 和容器的真正运行（CRI）；</li><li>kube-proxy 负责为 Service 提供 cluster 内部的服务发现和负载均衡；</li></ul><p>当然了除了上面的这些核心组件，还有一些推荐的插件：</p><ul><li>kube-dns 负责为整个集群提供 DNS 服务</li><li>Ingress Controller 为服务提供外网入口</li><li>Heapster 提供资源监控</li><li>Dashboard 提供 GUI</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 云原生 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>天天商城</title>
      <link href="/blog/2023/03/10/10/"/>
      <url>/blog/2023/03/10/10/</url>
      
        <content type="html"><![CDATA[<p>我开发的这个系统是基于b2c的电商系统，我来给您介绍一下这个项目的架构，这个系统一共是分成两个子系统，分别是前台和后台，前台使用主流的前端框架Vue ，使用Es6的开发规范 ，采用模块化的开发模式。 后端部分采用SpringCloud架构 ，利用SpringBoot构建应用。我主要参与的是后台的开发，主要包括商品，订单模块。</p><p>商品管理的目的主要是有三个，一是让用户快速地找到商品，可以根据关键词或者类目来搜索。二是为同类型的商品提供标准属性和属性值，便于统一管理商品。三是商品的上架和下架。商品模块在建模上就很复杂，商品信息要拆分成spu和sku两种，spu存放的是商品的主要信息，sku存放的是商品的组合信息，比如说苹果手机，不同的内存和颜色就可以产生不同的sku记录。还有比较复杂的是规格属性和销售属性的参数定义，他们是由三级分类组织起来的，规格属性还有分组，比如说1主体：入网型号，品牌，生产日期；2基本信息：运营商标识，机身重量；3cpu信息：cpu品牌，型号，只有sku才有明确的销售属性，比如颜色，内存，我们单独设计了属性表，来存放属性的类型和值，spu，sku详情表里存放了属性表的id，后来发现按照统一的参数去创建数据表的字段查询性能不好，在数据库建模的时候，就不能按照统一的参数去创建数据表的字段，然后spu数据表里面商品记录用json格式的字段去存储每种商品的参数值，用户根据参数来搜索商品，不能直接搜索参数字段的数据，参数类型的字段是json的，mysql索引对字符串的优化是不够的，即使给json字段设置了索引，条件查询的速度也不是很理想，所以json字段的数据只在前端渲染商品信息的时候会用到，并不用他那来检索商品，商品检索我做成了统一的es模式，把商品概要信息呢存储在es里边，比如说用户去搜索i七cpu的笔记本，我们就让程序到es中去检索参数有cpu并且是i七的笔记本数据，那么es返回这个商品的属性值，最后呢前端程序把数据渲染成页面就可以了,再有就是添加商品的时候我们要去设置这个商品的一些属性信息,比如说商品的介绍,还有商品的单价,就拿商品的售价来说吧,如果不去人工二次三次的审核,一旦这个商品的价格录入错了啊发布到网上以后那么用户下了订单买了这样的商品那应该怎么去处理呢对不对,所以呢我们在发布商品的时候应该有一个审核的步骤,我们把业务呢设计成是售价五百元以内的商品一个人审核就可以了,五百元以上的商品需要两个人去审核然后才可以,上架并且呢还要去记录谁改动过商品的信息那么这些内容啊都是要进入备案的,另外呢很多模块的改动都会关联到商品模块,比如说品牌管理栏目删除了一个品牌,那么这个品牌关联的商品和订单数据要不要连带删除呢,像这样的问题很多</p><p>访问量，hyperloglog，pfadd page1:uv uesrid     pfcount</p><p>排行榜，sortedset   zadd order 110 userid zrange从小到大，zrevrange</p><h1 id="oss"><a href="#oss" class="headerlink" title="oss"></a>oss</h1>   <dependency>        <groupId>com.alibaba.cloud</groupId>        <artifactId>spring-cloud-starter-alicloud-oss</artifactId>        <version>2.2.0.RELEASE</version>      </dependency><p> alicloud:<br>      access-key: LTAI4FwvfjSycd1APnuG9bjj<br>      secret-key: O6xaxyiWfSIitcOkSuK27ju4hXT5Hl<br>      oss:<br>        endpoint: oss-cn-beijing.aliyuncs.com<br>        bucket: gulimall-hello</p><p>跨域问题</p><h2 id="OAuth2"><a href="#OAuth2" class="headerlink" title="OAuth2"></a>OAuth2</h2><p>注册开发者账号，appid和AppSecret，并配置后回调的域名了</p><p><img src="https://ask.qcloudimg.com/http-save/4069933/m9kd4b9pdm.png?imageView2/2/w/2560/h/7000" alt="img"></p><h1 id="elasticsearch"><a href="#elasticsearch" class="headerlink" title="elasticsearch"></a>elasticsearch</h1><p>下载镜像文件</p><p>配置挂载数据文件夹</p><p>docker run —name elasticsearch -p 9200:9200 -p 9300:9300 </p><p>-e  “discovery.type=single-node” </p><p>-e ES_JAVA_OPTS=”-Xms64m -Xmx512m” </p><p>-v</p><p>/mydata/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml </p><p>-v /mydata/elasticsearch/data:/usr/share/elasticsearch/data </p><p>-v  /mydata/elasticsearch/plugins:/usr/share/elasticsearch/plugins </p><p>-d elasticsearch:7.4.2 </p><p>docker run —name kibana \</p><p>-e ELASTICSEARCH_HOSTS=<a href="http://192.168.163.131:9200">http://192.168.163.131:9200</a> \</p><p>-p 5601:5601 \</p><p>-d kibana:7.4.2</p><p>match即全文检索，对检索字段进行分词匹配，会按照响应的评分 _score 排序，原理是倒排索引</p><h1 id="安装IK分词器"><a href="#安装IK分词器" class="headerlink" title="\安装IK分词器**"></a><strong><em>\</em>安装IK分词器**</strong></h1><p>给 es 配置自定义词库</p><p>vim /mydata/elasticsearch/plugins/ik/config/IKAnalyzer.cfg.xml</p><p>&lt;?xml version=”1.0” encoding=”UTF-8”?&gt;</p><properties><comment>IK Analyzer 扩展配置</comment><!--用户可以在这里配置自己的扩展字典 --><entry key="ext_dict"></entry><!--用户可以在这里配置自己的扩展停止词字典--><entry key="ext_stopwords"></entry><!--用户可以在这里配置远程扩展字典 --><!-- <entry key="remote_ext_dict">words_location</entry> --><entry key="remote_ext_dict">http://192.168.163.131/fenci.txt</entry><!--用户可以在这里配置远程扩展停止词字典--><!-- <entry key="remote_ext_stopwords">words_location</entry> --></properties><h1 id="下单流程（事务）"><a href="#下单流程（事务）" class="headerlink" title="下单流程（事务）"></a>下单流程（事务）</h1><p>通过拦截器判断是否已登陆</p><p>来到结算页面，点击提交订单</p><p>检验token，幂等性接口，通过lua脚本删除token</p><p>创建订单、订单项等信息</p><p>验证价格</p><p>调用远程锁定库存的方法，他本身是事务的（如果远程锁定库存成功，但是因为网络原因没返回，超时机制，下单回滚，但是库存扣了）</p><p>删除购物车里的数据</p><p>远程扣减积分（下面的方法出现了问题，库存已经提交，无法回滚）</p><p>跳到支付页面</p><p> 用seata，默认是at模式，不适合高并发场景（加锁，串行化，效率低）</p><p>改用rabbitmq的延时队列，来实现可靠消息＋最终一致性</p><p>加了两张表，锁定库存工作单和工作单详情，设置1min未支付就关闭订单，2min后，检查订单不存在或者被取消，就进行解锁库存</p><h1 id="整合Sentinel"><a href="#整合Sentinel" class="headerlink" title="整合Sentinel"></a>整合Sentinel</h1><p>1）、导入依赖 spring-cloud-starter-alibaba-sentinel </p><p>2）、下载sentinel控制台 </p><p>3）、配置 sentinel 控制台地址信息 </p><p>4）、配置 sentinel 控制台调整参数</p><p><img src="https://user-images.githubusercontent.com/9434884/48189035-25883980-e37a-11e8-8f25-3f3f5be23f0e.png" alt="dashboard-add-rule" style="zoom:50%;" /></p><p>2、每一个微服务都导入 actuator ：并配合 management.endpoints.web.exposure.include=* </p><p>3、自定义 sentinel 流控返回的数据 </p><p>4、使用Sentinel来保护feign远程调用，</p><p>熔断</p><p>RT：平均响应时间；</p><ul><li>慢调用比例 (<code>SLOW_REQUEST_RATIO</code>)：选择以慢调用比例作为阈值，需要设置允许的慢调用 RT（即最大的响应时间），请求的响应时间大于该值则统计为慢调用。当单位统计时长（<code>statIntervalMs</code>）内请求数目大于设置的最小请求数目，并且慢调用的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求响应时间小于设置的慢调用 RT 则结束熔断，若大于设置的慢调用 RT 则会再次被熔断。</li><li>异常比例 (<code>ERROR_RATIO</code>)：当单位统计时长（<code>statIntervalMs</code>）内请求数目大于设置的最小请求数目，并且异常的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。异常比率的阈值范围是 <code>[0.0, 1.0]</code>，代表 0% - 100%。</li><li><p>异常数 (<code>ERROR_COUNT</code>)：当单位统计时长内的异常数目超过阈值之后会自动进行熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。</p><p>1）、调用方的熔断保护：feign.sentinel.enable=true </p></li></ul><p>2）、调用方手动指定远程服务的降级策略。远程服务被降级处理。触发我们的熔断回调方法 </p><p>3）、超大浏览的时候，必须牺牲一些远程服务。在服务的提供方（远程服务）指定降级策略； 提供方是在运行，但是不允许自己的业务逻辑，返回的是默认的降级数据（限流的数据） </p><p>5、自定义受保护的资源 1）、代码 try (Entry entry = SphU.entry(“seckillSkus”)) { //业务逻辑 } catch(Exception e) {} 2）、基于注解@SentinelResource(value = “getCurrentSeckillSkusResource”,blockHandler = “blockHandler”)</p><p>网关层</p><p>导入依赖 spring-cloud-alibaba-sentinel-getway</p><p>配置更详细，可以根据remote host,header,cookie进行限流</p><p>@Configuration</p><p>public class SentinelGatewayConfig {</p><p>  public SentinelGatewayConfig() {</p><p>​    GatewayCallbackManager.setBlockHandler(new BlockRequestHandler() {</p><p>​      //网关限流了请求，就会调用此回调</p><p>​      @Override</p><p>​      public Mono<ServerResponse> handleRequest(ServerWebExchange exchange, Throwable t) {</p><p>​        R error = R.error(BizCodeEnume.TOO_MANY_REQUEST.getCode(), BizCodeEnume.TOO_MANY_REQUEST.getMessage());</p><p>​        String errorJson = JSON.toJSONString(error);</p><p>​        Mono<ServerResponse> body = ServerResponse.ok().body(Mono.just(errorJson), String.class);</p><p>​        return body;</p><p>​      }</p><p>​    });</p><p>  }</p><p>}</p><h1 id="配置跨域"><a href="#配置跨域" class="headerlink" title="配置跨域"></a>配置跨域</h1><p>@Configuration</p><p>public class GulimallCorsConfiguration {</p><p>  @Bean</p><p>  public CorsWebFilter corsWebFilter() {</p><p>​    UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();</p><p>​    CorsConfiguration corsConfiguration = new CorsConfiguration();</p><p>​    corsConfiguration.addAllowedHeader(“*”);</p><p>​    corsConfiguration.addAllowedMethod(“*”);</p><p>​    corsConfiguration.addAllowedOrigin(“*”);</p><p>​    corsConfiguration.setAllowCredentials(true);</p><p>​    source.registerCorsConfiguration(“/**”,corsConfiguration);</p><p>​    return new CorsWebFilter(source);</p><p>  }</p><p>}</p><h2 id="ShardingSphere"><a href="#ShardingSphere" class="headerlink" title="ShardingSphere"></a>ShardingSphere</h2>]]></content>
      
      
      <categories>
          
          <category> 天天商城 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 天天商城 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gateway原理</title>
      <link href="/blog/2022/12/17/6/"/>
      <url>/blog/2022/12/17/6/</url>
      
        <content type="html"><![CDATA[<ul><li><p>Spring Cloud Gateway 使用了 Spring WebFlux 非阻塞网络框架，网络层默认使用了高性能非阻塞的 Netty Server，解决了 Spring Cloud Zuul 因为阻塞的线程模型带来的性能下降的问题。</p><p>Gateway 本身是一个 Spring Boot 应用，它处理请求是逻辑是根据配置的路由对请求进行预处理和转发。</p><ul><li><p><strong>路由判断</strong>：客户端的请求到达网关后，先经过 Gateway Handler Mapping 处理，这里面会做断言（Predicate）判断，看下符合哪个路由规则，这个路由映射后端的某个服务。</p><p><strong>请求过滤</strong>：然后请求到达 Gateway Web Handler，这里面有很多过滤器，组成过滤器链（Filter Chain），这些过滤器可以对请求进行拦截和修改，比如添加请求头、参数校验等等，有点像净化污水。然后将请求转发到实际的后端服务。这些过滤器逻辑上可以称作 Pre-Filters，Pre 可以理解为“在…之前”。</p><p><strong>服务处理</strong>：后端服务会对请求进行处理。</p><p><strong>响应过滤</strong>：后端处理完结果后，返回给 Gateway 的过滤器再次做处理，逻辑上可以称作 Post-Filters，Post 可以理解为“在…之后”。</p><p><strong>响应返回</strong>：响应经过过滤处理后，返回给客户端。</p></li></ul><p>下图展示了 Spring Cloud Gateway 的基本工作原理，过程比较简单。</p><p><img src="https://blog-static.fintopia.tech/6bcb3ca84a22808002a2329c95f04684.jpeg" alt="img"></p><p>Gateway 在启动时会创建 Netty Server，由它接收来自 Client 的请求。收到请求后根据路由的匹配条件找到第一个满足条件的路由，然后请求在被该路由配置的过滤器处理后由 Netty Client 转到目标服务。服务返回响应后会再次被过滤器处理，最后返回给 Client。</p><p>下面基于 Spring Cloud Gateway <code>2.2.2.RELEASE</code> 版本，详细介绍一下 Gateway 的实现原理。</p></li></ul><p>  Gateway 使用了 Spring WebFlux 框架，该框架处理请求的入口在类 <code>DispatcherHandler</code> 。它会根据提供的 <code>HandlerMapping</code> 来获取处理请求的 <code>Handler</code> 方法。Gateway 应用对 <code>HandlerMapping</code> 的实现是 <code>RoutePredicateHandlerMapping</code>。</p><p>  下图展示了 Gateway 接收请求的过程。</p><ol><li>进来的请求由 <code>DispatcherHandler</code> 处理。</li><li><code>DispatcherHandler</code> 根据 <code>RoutePredicateHandlerMapping</code> 获取 <code>Handler</code> 方法。</li><li><code>RoutePredicateHandlerMapping</code> 依赖 <code>RouteLocator</code> 获取所有路由配置并根据匹配条件打到请求匹配的路由。</li><li><code>RoutePredicateHandlerMapping</code> 把请求交给 <code>FilteringWebHandler</code> 处理。</li><li><code>FilteringWebHandler</code> 从请求匹配的路由获取对应的路由 Filter，并和全局 Filter 合并构造 <code>GatewayFilterChain</code>，请求最终由 <code>GatewayFilterChain</code> 里的 Filter 按顺序处理。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Spring Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nacos原理</title>
      <link href="/blog/2022/12/17/7/"/>
      <url>/blog/2022/12/17/7/</url>
      
        <content type="html"><![CDATA[<p><img src="C:\Users\熊强\Pictures\image-20230329140220294.png" alt="image-20230329140220294"></p><ul><li>Spring Cloud集成Nacos的实现过程 在Spring-cloud-commons包下的META-INF/spring.factories中包含自动装配的配置信息,其中AutoServiceRegistrationAutoConfiguration就是服务注册相关的配置类,</li><li>在AutoServiceRegistrationAutoConfiguration配置类中，注入了AutoServiceRegistration实例。AbstractAutoServiceRegistration抽象类实现了该接口，最终NacosAutoServiceRegistration继承AbstractAutoServiceRegistration</li></ul><p>客户端最终调用了reqApi方法,把信息封装成params的map向Nacos Server /nacos/v1/ns/instance 接口发送了一个POST请求，把当前实例注册进去，到这里整个客户端的核心注册流程就分析完了</p><p>nacos服务端提供接口请求地址，/v1/ns/instance，具体代码在nacos-naming下的InstanceController</p><p>主要逻辑为</p><ul><li>创建一个空服务，初始化serviceMap</li><li>getService，从serviceMap中根据namespaceid和serviceName得到一个服务对象</li><li>调用addInstance添加到服务对象</li></ul><h2 id="Nacos-Server-的注册表结构"><a href="#Nacos-Server-的注册表结构" class="headerlink" title="Nacos Server 的注册表结构"></a><strong>Nacos Server 的注册表结构</strong></h2><p>说到服务注册，那么首先需要关注的是注册表结构是怎么设计的，Nacos的注册表结构设计方式是一个双重Map结构，定义如下：</p><p><img src="https://pic3.zhimg.com/80/v2-2ee674b09917e7554326d9e48dcb7eb6_1440w.webp" alt="img"></p><p>源码中注释其实已经解释这个双重Map数据结构的存储结构，最外层的Map的Key为Namespace，Value为一个Map，内层的Map的Key为group::serviceName，Value为Service对象。Service对象中也有一个Map的数据结构，如下：</p><p><img src="https://pic4.zhimg.com/80/v2-6a12434e78899e896fbfed4776387cdf_1440w.webp" alt="img"></p><p>Map的Key值为Cluster的名字，Value为Cluster对象，Cluster对象中有两个Set的数据结构，用来存储Instance，这个Instance才是真正的客户端注册过来的实例信息。</p><p><img src="https://pic2.zhimg.com/80/v2-56e651db405fcbc1f8e00a2c29361cf5_1440w.webp" alt="img"></p><h4 id=""><a href="#" class="headerlink" title=" "></a> </h4><p>客户端发送http post请求，请求地址为/v1/ns/instance，服务端的<code>InstanceController</code>接收和响应客户端的请求。</p><h4 id="InstanceController"><a href="#InstanceController" class="headerlink" title="InstanceController"></a>InstanceController</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">@CanDistro</span><br><span class="line">@PostMapping</span><br><span class="line">@Secured(parser = NamingResourceParser.class, action = ActionTypes.WRITE)</span><br><span class="line">public String register(HttpServletRequest request) throws Exception &#123;</span><br><span class="line">    </span><br><span class="line">    //从request中获取客户端传递的namespaceId</span><br><span class="line">    final String namespaceId = WebUtils.optional(request, CommonParams.NAMESPACE_ID, Constants.DEFAULT_NAMESPACE_ID);</span><br><span class="line">    //从request中获取客户端传递的serviceName</span><br><span class="line">    final String serviceName = WebUtils.required(request, CommonParams.SERVICE_NAME);</span><br><span class="line">    //检查服务名是否合法</span><br><span class="line">    NamingUtils.checkServiceNameFormat(serviceName);</span><br><span class="line">    </span><br><span class="line">    //从request中获取客户端传递的参数构造instance对象</span><br><span class="line">    final Instance instance = HttpRequestInstanceBuilder.newBuilder()</span><br><span class="line">            .setDefaultInstanceEphemeral(switchDomain.isDefaultInstanceEphemeral()).setRequest(request).build();</span><br><span class="line"> //实际调的是 serviceManager.registerInstance(namespaceId, serviceName, coreInstance);   </span><br><span class="line">InstanceOperatorServiceImpl.getInstanceOperator().registerInstance(namespaceId, serviceName, instance);</span><br><span class="line">    return &quot;ok&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="ServiceManager"><a href="#ServiceManager" class="headerlink" title="ServiceManager"></a>ServiceManager</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public void registerInstance(String namespaceId, String serviceName, Instance instance) throws NacosException &#123;</span><br><span class="line">    </span><br><span class="line">    //1.创建一个空的服务</span><br><span class="line">    createEmptyService(namespaceId, serviceName, instance.isEphemeral());</span><br><span class="line">    </span><br><span class="line"> //2.从缓存中获取服务</span><br><span class="line">    Service service = getService(namespaceId, serviceName);</span><br><span class="line">    </span><br><span class="line">    //3.检查服务是否为null</span><br><span class="line">    checkServiceIsNull(service, namespaceId, serviceName);</span><br><span class="line">    </span><br><span class="line"> //4.添加实例</span><br><span class="line">    addInstance(namespaceId, serviceName, instance.isEphemeral(), instance);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="createEmptyService"><a href="#createEmptyService" class="headerlink" title="createEmptyService"></a>createEmptyService</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">public void createEmptyService(String namespaceId, String serviceName, boolean local) throws NacosException &#123;</span><br><span class="line"> //如果不存在就创建一个服务</span><br><span class="line">    createServiceIfAbsent(namespaceId, serviceName, local, null);</span><br><span class="line">&#125;</span><br><span class="line">public void createServiceIfAbsent(String namespaceId, String serviceName, boolean local, Cluster cluster)</span><br><span class="line">            throws NacosException &#123;</span><br><span class="line">    //从内部的serviceMap中获取service</span><br><span class="line">    Service service = getService(namespaceId, serviceName);</span><br><span class="line">    //假如我们是第一次注册服务，那么这里从缓存中得到的就是null</span><br><span class="line">    if (service == null) &#123;</span><br><span class="line">        </span><br><span class="line">        Loggers.SRV_LOG.info(&quot;creating empty service &#123;&#125;:&#123;&#125;&quot;, namespaceId, serviceName);</span><br><span class="line">  //实例化service</span><br><span class="line">        service = new Service();</span><br><span class="line">        //设置服务名</span><br><span class="line">        service.setName(serviceName);</span><br><span class="line">        //设置服务归属的命名空间</span><br><span class="line">        service.setNamespaceId(namespaceId);</span><br><span class="line">        //设置服务归属的组</span><br><span class="line">        service.setGroupName(NamingUtils.getGroupName(serviceName));</span><br><span class="line">        // now validate the service. if failed, exception will be thrown</span><br><span class="line">        //设置服务的最后修改时间为当前系统时间</span><br><span class="line">        service.setLastModifiedMillis(System.currentTimeMillis());</span><br><span class="line">        //重新计算服务的MD5值</span><br><span class="line">        service.recalculateChecksum();</span><br><span class="line">        //由于上一步传入进来的cluster等于null，所以此处不执行</span><br><span class="line">        if (cluster != null) &#123;</span><br><span class="line">            cluster.setService(service);</span><br><span class="line">            service.getClusterMap().put(cluster.getName(), cluster);</span><br><span class="line">        &#125;</span><br><span class="line">        //验证服务是否合法，比如服务名</span><br><span class="line">        service.validate();</span><br><span class="line">        </span><br><span class="line">        //添加服务并且初始化服务</span><br><span class="line">        putServiceAndInit(service);</span><br><span class="line">        //local等于true，临时实例，以下代码不执行</span><br><span class="line">        if (!local) &#123;</span><br><span class="line">            addOrReplaceService(service);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="addInstance"><a href="#addInstance" class="headerlink" title="addInstance"></a>addInstance</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">public void addInstance(String namespaceId, String serviceName, boolean ephemeral, Instance... ips)</span><br><span class="line">            throws NacosException &#123;</span><br><span class="line">    //根据namespaceId、serviceName以及是否是临时实例，创建一个key，由于此时我们注册的是临时实例，所以key为com.alibaba.nacos.naming.iplist.ephemeral.&#123;namespaceId&#125;.##.&#123;serviceName&#125;</span><br><span class="line">    String key = KeyBuilder.buildInstanceListKey(namespaceId, serviceName, ephemeral);</span><br><span class="line">    </span><br><span class="line">    //从缓存中获取上一步中创建的空service</span><br><span class="line">    Service service = getService(namespaceId, serviceName);</span><br><span class="line">    </span><br><span class="line">    synchronized (service) &#123;</span><br><span class="line">     //更新实例并返回该服务下的所有实例列表</span><br><span class="line">        List&lt;Instance&gt; instanceList = addIpAddresses(service, ephemeral, ips);</span><br><span class="line">        </span><br><span class="line">        //创建一个instances对象，用于传递实例列表</span><br><span class="line">        Instances instances = new Instances();</span><br><span class="line">        instances.setInstanceList(instanceList);</span><br><span class="line">        </span><br><span class="line">        //触发一个服务变更的通知以及向集群中的其他nacos节点同步实例数据</span><br><span class="line">        consistencyService.put(key, instances);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​<br>      for (Instance instance : ips) {<br>         //首次注册，clusterMap中不包含当前实例的clusterName的key<br>            if (!service.getClusterMap().containsKey(instance.getClusterName())) {<br>             //实例化cluster，并通过构造函数传递集群的名字，以及当前集群归属于哪一个service<br>                Cluster cluster = new Cluster(instance.getClusterName(), service);<br>                //集群初始化,内部还是开启了一个心跳检查的定时任务，先不管<br>                cluster.init();<br>                //向service内部的clusterMap中设置cluster<br>                service.getClusterMap().put(instance.getClusterName(), cluster);<br>                Loggers.SRV_LOG<br>                        .warn(“cluster: {} not found, ip: {}, will create new cluster with default configuration.”,<br>                                instance.getClusterName(), instance.toJson());<br>            }</p><h2 id="init"><a href="#init" class="headerlink" title="init"></a>init</h2><p>注册了一个notifier的定时任务，<code>Notifier</code>实现了<code>Runnable</code>接口，</p><p>它的<code>run</code>方法：如果ArrayBlockingQueue中没有数据，take方法会阻塞，直到从队列中取到数据，handle(pair);</p><p>它的<code>handle</code>方法：遍历listeners，if (action == DataOperation.CHANGE) {<br>         <em>//调用listener的onChange方法</em><br>          listener.onChange(datumKey, dataStore.get(datumKey).value);<br>          continue;<br>        }</p><p>onChange：updateIPs(value.getInstanceList(), KeyBuilder.matchEphemeralInstanceListKey(key));</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">public void updateIPs(Collection&lt;Instance&gt; instances, boolean ephemeral) &#123;</span><br><span class="line"> //创建一个空的map，用户存储实例数据</span><br><span class="line">    Map&lt;String, List&lt;Instance&gt;&gt; ipMap = new HashMap&lt;&gt;(clusterMap.size());</span><br><span class="line">    //遍历clusterMap，copyOnWrite，考虑并发读写问题</span><br><span class="line">    for (String clusterName : clusterMap.keySet()) &#123;</span><br><span class="line">        ipMap.put(clusterName, new ArrayList&lt;&gt;());</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    //遍历待添加的实例列表</span><br><span class="line">    for (Instance instance : instances) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            if (instance == null) &#123;</span><br><span class="line">                Loggers.SRV_LOG.error(&quot;[NACOS-DOM] received malformed ip: null&quot;);</span><br><span class="line">                continue;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            //如果实例归属的集群名等于空</span><br><span class="line">            if (StringUtils.isEmpty(instance.getClusterName())) &#123;</span><br><span class="line">             //则使用默认的集群名DEFAULT</span><br><span class="line">                instance.setClusterName(UtilsAndCommons.DEFAULT_CLUSTER_NAME);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            //如果服务的clusterMap中不包含clusterName key，由于在前几步中已经添加过了</span><br><span class="line">            if (!clusterMap.containsKey(instance.getClusterName())) &#123;</span><br><span class="line">                Loggers.SRV_LOG</span><br><span class="line">                        .warn(&quot;cluster: &#123;&#125; not found, ip: &#123;&#125;, will create new cluster with default configuration.&quot;,</span><br><span class="line">                                instance.getClusterName(), instance.toJson());</span><br><span class="line">                //实例化cluster</span><br><span class="line">                Cluster cluster = new Cluster(instance.getClusterName(), this);</span><br><span class="line">                //初始化</span><br><span class="line">                cluster.init();</span><br><span class="line">                //添加到clusterMap中</span><br><span class="line">                getClusterMap().put(instance.getClusterName(), cluster);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            //首次注册，等于null</span><br><span class="line">            List&lt;Instance&gt; clusterIPs = ipMap.get(instance.getClusterName());</span><br><span class="line">            if (clusterIPs == null) &#123;</span><br><span class="line">                clusterIPs = new LinkedList&lt;&gt;();</span><br><span class="line">                ipMap.put(instance.getClusterName(), clusterIPs);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            //将实例添加到对应的cluster中</span><br><span class="line">            clusterIPs.add(instance);</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            Loggers.SRV_LOG.error(&quot;[NACOS-DOM] failed to process ip: &quot; + instance, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    //遍历ipMap，并将新注册的实例添加到clusterMap中</span><br><span class="line">    for (Map.Entry&lt;String, List&lt;Instance&gt;&gt; entry : ipMap.entrySet()) &#123;</span><br><span class="line">        //make every ip mine</span><br><span class="line">        List&lt;Instance&gt; entryIPs = entry.getValue();</span><br><span class="line">        //请自行跟踪updateIps方法，下文的问题2的解答在此处</span><br><span class="line">        clusterMap.get(entry.getKey()).updateIps(entryIPs, ephemeral);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    //更新service的最后修改时间为当前系统时间</span><br><span class="line">    setLastModifiedMillis(System.currentTimeMillis());</span><br><span class="line">    //底层通过UDP socket 向所有订阅了该服务的客户端推送服务，不在主线中，先不管</span><br><span class="line">    getPushService().serviceChanged(this);</span><br><span class="line">    </span><br><span class="line">   //v2版本新增</span><br><span class="line">    ApplicationUtils.getBean(DoubleWriteEventListener.class).doubleWriteToV2(this, ephemeral);</span><br><span class="line">    StringBuilder stringBuilder = new StringBuilder();</span><br><span class="line">    </span><br><span class="line">    //遍历所有实例，包含临时和持久化实例，输出日志</span><br><span class="line">    for (Instance instance : allIPs()) &#123;</span><br><span class="line">        stringBuilder.append(instance.toIpAddr()).append(&#x27;_&#x27;).append(instance.isHealthy()).append(&#x27;,&#x27;);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    Loggers.EVT_LOG.info(&quot;[IP-UPDATED] namespace: &#123;&#125;, service: &#123;&#125;, ips: &#123;&#125;&quot;, getNamespaceId(), getName(),</span><br><span class="line">            stringBuilder.toString());</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> springcloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> springcloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenFeign原理</title>
      <link href="/blog/2022/12/17/8/"/>
      <url>/blog/2022/12/17/8/</url>
      
        <content type="html"><![CDATA[<p>Feign底层默认是JDK自带的HttpURLConnection,它是单线程发送HTTP请求的，不能配置线程池，我们使用<br>Ckhttp或者HttpClient来发送http请求，并且它们两个都支持线程池。</p><p>1、在 Spring 项目启动阶段，服务 A 的OpenFeign 框架会发起一个主动的扫包流程。<br>2、从指定的目录下扫描并加载所有被 @FeignClient 注解修饰的接口，然后将这些接口转换成 Bean，统一交给 Spring 来管理。<br>3、根据这些接口会经过 MVC Contract 协议解析，将方法上的注解都解析出来，放到 MethodMetadata 元数据中。<br>4、基于上面加载的每一个 FeignClient 接口，会生成一个动态代理对象，指向了一个包含对应方法的 MethodHandler 的 HashMap。MethodHandler 对元数据有引用关系。生成的动态代理对象会被添加到 Spring 容器中，并注入到对应的服务里。<br>5、服务 A 调用接口，准备发起远程调用。<br>6、从动态代理对象 Proxy 中找到一个 MethodHandler 实例，生成 Request，包含有服务的请求 URL(不包含服务的 IP)。<br>7、经过负载均衡算法找到一个服务的 IP 地址，拼接出请求的 URL<br>8、服务 B 处理服务 A 发起的远程调用请求，执行业务逻辑后，返回响应给服务 A。</p><p>(1)@EnableFeignClients 这个注解使用 Spring 框架的 Import 注解导入了 FeignClientsRegistrar 类，开始了 OpenFeign 组件的加载。PassJava 示例代码如下所示。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 启动类加上这个注解 </span><br><span class="line">@EnableFeignClients(basePackages = &quot;com.jackson0714.passjava.member.feign&quot;) </span><br><span class="line"> </span><br><span class="line">// EnableFeignClients 类还引入了 FeignClientsRegistrar 类 </span><br><span class="line">@Import(FeignClientsRegistrar.class) </span><br><span class="line">public @interface EnableFeignClients &#123; </span><br><span class="line">  ... </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><p>(2)FeignClientsRegistrar 负责 Feign 接口的加载。</p><p>源码如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@Override </span><br><span class="line">public void registerBeanDefinitions(AnnotationMetadata metadata, </span><br><span class="line">      BeanDefinitionRegistry registry) &#123; </span><br><span class="line">   // 注册配置 </span><br><span class="line">   registerDefaultConfiguration(metadata, registry); </span><br><span class="line">   // 注册 FeignClient </span><br><span class="line">   registerFeignClients(metadata, registry); </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><p>(3)registerFeignClients 会扫描指定包。</p><p>核心源码如下，调用 find 方法来查找指定路径 basePackage 的所有带有 @FeignClients 注解的带有 @FeignClient 注解的类、接口。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Set&lt;BeanDefinition&gt; candidateComponents = scanner </span><br><span class="line">      .findCandidateComponents(basePackage); </span><br></pre></td></tr></table></figure><p>(4)只保留带有 @FeignClient 的接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 判断是否是带有注解的 Bean。 </span></span><br><span class="line"><span class="keyword">if</span> (candidateComponent <span class="keyword">instanceof</span> AnnotatedBeanDefinition) &#123; </span><br><span class="line">  <span class="comment">// 判断是否是接口 </span></span><br><span class="line">   <span class="type">AnnotatedBeanDefinition</span> <span class="variable">beanDefinition</span> <span class="operator">=</span> (AnnotatedBeanDefinition) candidateComponent; </span><br><span class="line">   <span class="type">AnnotationMetadata</span> <span class="variable">annotationMetadata</span> <span class="operator">=</span> beanDefinition.getMetadata(); </span><br><span class="line">  <span class="comment">// @FeignClient 只能指定在接口上。 </span></span><br><span class="line">   Assert.isTrue(annotationMetadata.isInterface(), </span><br><span class="line">         <span class="string">&quot;@FeignClient can only be specified on an interface&quot;</span>); </span><br></pre></td></tr></table></figure><p>在创建 FeignClient Bean 的过程中就会去生成动态代理对象。调用接口时，其实就是调用动态代理对象的方法来发起请求的。</p><p>分析动态代理的入口方法为 getObject()。源码如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Targeter targeter = get(context, Targeter.class); </span><br><span class="line">return (T) targeter.target(this, builder, context, </span><br><span class="line">      new HardCodedTarget&lt;&gt;(this.type, this.name, url)); </span><br></pre></td></tr></table></figure><p>接着调用 target 方法这一块，里面的代码真的很多很细，我把核心的代码拿出来给大家讲下，这个 target 会有两种实现类：</p><p>DefaultTargeter 和 HystrixTargeter。而不论是哪种 target，都需要去调用 Feign.java 的 builder 方法去构造一个 feign client。</p><p>在构造的过程中，依赖 ReflectiveFeign 去构造。源码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">// 省略部分代码 </span><br><span class="line">public class ReflectiveFeign extends Feign &#123; </span><br><span class="line">  // 为 feign client 接口中的每个接口方法创建一个 methodHandler </span><br><span class="line"> public &lt;T&gt; T newInstance(Target&lt;T&gt; target) &#123; </span><br><span class="line">    for(...) &#123; </span><br><span class="line">      methodToHandler.put(method, handler); </span><br><span class="line">    &#125; </span><br><span class="line">    // 基于 JDK 动态代理的机制，创建了一个 passjava-study 接口的动态代理，所有对接口的调用都会被拦截，然后转交给 handler 的方法。 </span><br><span class="line">    InvocationHandler handler = factory.create(target, methodToHandler); </span><br><span class="line">    T proxy = (T) Proxy.newProxyInstance(target.type().getClassLoader(), </span><br><span class="line">          new Class&lt;?&gt;[] &#123;target.type()&#125;, handler); </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><p>ReflectiveFeign 做的工作就是为带有 @FeignClient 注解的接口，创建出接口方法的动态代理对象。</p><p>比如示例代码中的接口 StudyTimeFeignService，会给这个接口中的方法 getMemberStudyTimeList 创建一个动态代理对象。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">@FeignClient(&quot;passjava-study&quot;) </span><br><span class="line">public interface StudyTimeFeignService &#123; </span><br><span class="line">    @RequestMapping(&quot;study/studytime/member/list/test/&#123;id&#125;&quot;) </span><br><span class="line">    public R getMemberStudyTimeList(@PathVariable(&quot;id&quot;) Long id); </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><p>创建动态代理的原理图如下所示：</p><p><img src="https://img.bestxq.live//20230329204430.png" alt="img"></p><p>解析 FeignClient 接口上各个方法级别的注解，比如远程接口的 URL、接口类型(Get、Post 等)、各个请求参数等。这里用到了 MVC Contract 协议解析，后面会讲到。</p><ul><li>然后将解析到的数据封装成元数据，并为每一个方法生成一个对应的 MethodHandler 类作为方法级别的代理。相当于把服务的请求地址、接口类型等都帮我们封装好了。这些 MethodHandler 方法会放到一个 HashMap 中。</li><li>然后会生成一个 InvocationHandler 用来管理这个 hashMap，其中 Dispatch 指向这个 HashMap。</li><li>然后使用 Java 的 JDK 原生的动态代理，实现了 FeignClient 接口的动态代理 Proxy 对象。这个 Proxy 会添加到 Spring 容器中。</li><li>当要调用接口方法时，其实会调用动态代理 Proxy 对象的 methodHandler 来发送请求。</li></ul><p>这个动态代理对象的结构如下所示，它包含了所有接口方法的 MethodHandler。</p><p><img src="https://img.bestxq.live//20230329204751.png" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> springcloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> springcloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CompletableFuture原理</title>
      <link href="/blog/2022/12/17/4/"/>
      <url>/blog/2022/12/17/4/</url>
      
        <content type="html"><![CDATA[<p>以Async结尾的方法，都是异步方法，对应的没有Async则是同步方法，一般都是一个异步方法对应一个同步方法。</p><p>以run开头的方法，其入口参数一定是无参的，并且没有返回值，类似于执行Runnable方法。</p><p>以supply开头的方法，入口也是没有参数的，但是有返回值</p><p>以Accept开头或者结尾的方法，入口参数是有参数，但是没有返回值</p><p>以Apply开头或者结尾的方法，入口有参数，有返回值</p><ol><li><p>CompletableFuture同时实现了两个接口，分别为Future和CompletionStage，CompletionStage是CompletableFuture提供的一些非常丰富的接口，可以借助这些接口来实现非常复杂的异步计算工作.</p><p>​    先来分析一下CompletableFuture的get方法的实现细节，CompletableFuture实现了Future的所有接口,包括两个get方法，一个是不带参数的get方法，一个是可以设置等待时间的get方法，首先来看一下CompletableFuture中不带参数的get方法的具体实现</p><p>result字段代表任务的执行结果，所以首先判断是否为null，为null则表示任务还没有执行结束，那么就会调用waitingGet方法来等待任务执行完成，如果result不为null，那么说明任务已经成功执行结束了，那么就调用reportGet来返回结果，下面先来看一下waitingGet方法的具体实现细节：</p><p>这个方法的实现时比较复杂的，方法中有几个地方需要特别注意，下面先来看一下spins是做什么的，根据注释，可以知道spins是用来在多核心环境下的自旋操作的，所谓自旋就是不断循环等待判断，从代码可以看出在多核心环境下，spins会被初始化为1 &lt;&lt; 8，然后在自旋的过程中如果发现spins大于0，那么就通过一个关键方法ThreadLocalRandom.nextSecondarySeed()来进行spins的更新操作，如果ThreadLocalRandom.nextSecondarySeed()返回的结果大于0，那么spins就减1，否则不更新spins。ThreadLocalRandom.nextSecondarySeed()方法其实是一个类似于并发环境下的random，是线程安全的。</p><p>​    分析完了不带参数的get方法（阻塞等待）之后，现在来分析一下带超时参数的get方法的具体实现细节：和不带参数的get方法一样，还是会判断任务是否已经执行完成了，如果完成了会调用reportGet方法来返回最终的执行结果（或者抛出异常），否则，会调用timedGet来进行超时等待，timedGet会等待一段时间，然后抛出超时异常（或者执行结束返回正常结果），下面是timedGet方法的具体细节：</p><p>在timedGet中不再使用spins来进行自旋，因为现在可以确定需要等待多少时间了。timedGet的逻辑和waitingGet的逻辑类似，毕竟都是在等待任务的执行结果。</p><p>   supplyAsync的具体执行流程，supplyAsync有两个版本，一个是不带Executor的，还有一个是指定Executor的，下面首先分析一下不指定Executor的</p><p>每个CompletableFuture持有一个Completion栈stack, 每个Completion持有一个CompletableFuture -&gt; dep, 如此递归循环下去，是层次很深的树形结构，所以想办法将其变成链表结构。</p><p>首先取出头结点，下图中灰色Completion结点，它会返回一个CompletableFuture, 同样也拥有一个stack，策略是遍历这个CompletableFuture的stack的每个结点，依次压入到当前CompletableFuture的stack中，关系如下箭头所示，灰色结点指的是处理过的结点。</p><p>第一个Completion结点返回的CompletableFuture, 将拥有的stack里面的所有结点都压入了当前CompletableFuture的stack里面</p><p>后续的Completion结点返回的CompletableFuture, 将拥有的stack里面的所有结点都压入了当前CompletableFuture的stack里面，重新构成了一个链表结构，后续也按照前面的逻辑操作，如此反复，便会遍历完所有的CompletableFuture, 这些CompletableFuture(叶子结点)的stack为空，也是结束条件</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 异步 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 异步 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Sentinel原理</title>
      <link href="/blog/2022/12/17/5/"/>
      <url>/blog/2022/12/17/5/</url>
      
        <content type="html"><![CDATA[<p>在 Sentinel 里面，所有的资源都对应一个资源名称（<code>resourceName</code>），每次资源调用都会创建一个 <code>Entry</code> 对象。Entry 可以通过对主流框架的适配自动创建，也可以通过注解的方式或调用 <code>SphU</code> API 显式创建。Entry 创建的时候，同时也会创建一系列功能插槽（slot chain），这些插槽有不同的职责，例如:</p><ul><li><strong><code>NodeSelectorSlot</code></strong> ：收集资源的路径，并将这些资源的调用路径，以树状结构存储起来，用于根据调用路径来限流降级；</li><li><strong><code>ClusterBuilderSlot</code></strong> ：用于存储资源的统计信息以及调用者信息，例如该资源的 RT, QPS, thread count 等等，这些信息将用作为多维度限流，降级的依据；</li><li><strong><code>StatisticSlot</code></strong> ：用于记录、统计不同纬度的 runtime 指标监控信息；</li><li><strong><code>SystemSlot</code></strong> ：通过系统的状态，例如 load1 等，来控制总的入口流量；</li><li><strong><code>AuthoritySlot</code></strong> ：根据配置的黑白名单和调用来源信息，来做黑白名单控制；</li><li><strong><code>FlowSlot</code></strong> ：用于根据预设的限流规则以及前面 slot 统计的状态，来进行流量控制；</li><li><strong><code>DegradeSlot</code></strong> ：通过统计信息以及预设的规则，来做熔断降级；</li></ul><p>总体的框架如下:</p><p><img src="C:\Users\熊强\Pictures\学习资料\20230329205232.png" alt="img"></p><p>　　从这个架构图可以发现，整个调用链中最核心的就是 <strong><code>StatisticSlot</code>(</strong>用于记录、统计不同纬度的 runtime 指标监控信息) 以及<strong><code>FlowSlot</code>(</strong>根据预设的限流规则以及前面 slot 统计的状态，来进行流量控制）.</p><p>　　Chain是链条的意思，从build的方法可看出，ProcessorSlotChain是一个链表，里面添加了很多个Slot。具体的实现需要到DefaultProcessorSlotChain中去看。</p><p>   着重注意两个 Slot ，就像我们使用的时候一样，我们需要配置规则，那么在Sentinel 中去校验这个规则的是 FlowSlot ，既然是一个做规则匹配的，那么进行匹配的数据是哪里来的呢？ 在Sentinel中他提供了一个Slot 来统计这些数据，然后交给FlowSlot进行校验，他就是<code>StatisticSlot</code>。我们首先来看<code>StatisticSlot</code>的entry方法中的实现逻辑：代码分成了两部分，第一部分是entry方法，该方法首先会触发后续slot的entry方法，即SystemSlot、FlowSlot、DegradeSlot等的规则，如果规则不通过，就会抛出BlockException，则会在node中统计被block的数量。反之会在node中统计通过的请求数和线程数等信息。第二部分是在exit方法中，当退出该Entry入口时，会统计rt的时间，并减少线程数。</p><p>　　我们可以看到 <code>node.addPassRequest()</code> 这段代码是在fireEntry执行之后执行的，这意味着，当前请求通过了sentinel的流控等规则，此时需要将当次请求记录下来，也就是执行 <code>node.addPassRequest()</code>这行代码，我们跟进去看看：首先我们知道这里的node是一个 DefaultNode 实例，在第一个NodeSelectorSlot 的entry方法中对资源进行了封装，封装成了一个DefaultNode。</p><ul><li><p>DefaultNode：保存着某个resource在某个context中的实时指标，每个DefaultNode都指向一个ClusterNode</p></li><li><p>ClusterNode：保存着某个resource在所有的context中实时指标的总和，同样的resource会共享同一个ClusterNode，不管他在哪个context中</p><p>　　从代码中我们可以看到，增加指标调用 addPass 是通过一个叫 ArrayMetric 的类，现在我们在进入 ArrayMetric 中看一下</p></li></ul><p>private final LeapArray<MetricBucket> data;<br>// SAMPLE_COUNT=2  INTERVAL=1000<br>public ArrayMetric(int sampleCount, int intervalInMs) {<br>    this.data = new OccupiableBucketLeapArray(sampleCount, intervalInMs);<br>}</p><p>public void addPass(int count) {<br>    WindowWrap<MetricBucket> wrap = data.currentWindow();<br>    wrap.value().addPass(count);<br>}</p><p><img src="C:\Users\熊强\Pictures\学习资料\20230425134324.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public abstract class LeapArray&lt;T&gt; &#123;</span><br><span class="line"></span><br><span class="line">    // 样本窗口的长度</span><br><span class="line">    protected int windowLengthInMs;25</span><br><span class="line">    // 一个时间窗的样本数量</span><br><span class="line">    protected int sampleCount;4</span><br><span class="line">    // 时间窗长度</span><br><span class="line">    protected int intervalInMs;100</span><br><span class="line"></span><br><span class="line">    // 采样的时间窗口数组</span><br><span class="line">    protected AtomicReferenceArray&lt;WindowWrap&lt;T&gt;&gt; array;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * LeapArray对象</span><br><span class="line">     * @param windowLength 时间窗口的长度，单位：毫秒</span><br><span class="line">     * @param intervalInSec 统计的间隔，单位：秒</span><br><span class="line">     */</span><br><span class="line">    public LeapArray(int windowLength, int intervalInSec) &#123;</span><br><span class="line">        this.windowLength = windowLength;</span><br><span class="line">        // 时间窗口的采样个数，默认为2个采样窗口</span><br><span class="line">        this.sampleCount = intervalInSec * 1000 / windowLength;</span><br><span class="line">        this.intervalInMs = intervalInSec * 1000;</span><br><span class="line"></span><br><span class="line">        this.array = new AtomicReferenceArray&lt;WindowWrap&lt;T&gt;&gt;(sampleCount);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public class WindowWrap&lt;T&gt; &#123;</span><br><span class="line">　　// yang窗口的长度</span><br><span class="line">    private final long windowLengthInMs;</span><br><span class="line">　　// 时间窗口的开始时间，单位是毫秒</span><br><span class="line">    private long windowStart;</span><br><span class="line">　　 //时间窗口的内容，在 WindowWrap 中是用泛型表示这个值的，但实际上就是 MetricBucket 类</span><br><span class="line">    private T value;</span><br><span class="line">    //......省略部分代码</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="C:\Users\熊强\Pictures\学习资料\image-20230329165726095.png" alt="image-20230329165726095.png"></p><p><img src="C:\Users\熊强\Pictures\学习资料\20230425142656.png" alt="img" style="zoom:33%;" /></p><p>可以很清晰的看出来在 <code>LeapArray</code> 中创建了一个 AtomicReferenceArray 数组，用来对时间窗口中的统计值进行采样。通过采样的统计值再计算出平均值，就是我们需要的最终的实时指标的值了。可以看到我在上面的代码中通过注释，标明了默认采样的时间窗口的个数是2个，这个值是怎么得到的呢？我们回忆一下 <code>LeapArray</code> 对象创建，是通过在 <code>StatisticNode</code> 中，new了一个 <code>ArrayMetric</code>，然后将参数一路往上传递后创建的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">private transient volatile Metric rollingCounterInSecond = new ArrayMetric(SampleCountProperty.SAMPLE_COUNT,IntervalProperty.INTERVAL);</span><br></pre></td></tr></table></figure><p>我们跟进获取当前窗口的方法 data.currentWindow() 中：</p><p>代码很长，我们逐步将其分解，我们实际可以把他分成以下几步：</p><ol><li>根据当前时间，算出该时间的timeId，并根据timeId算出当前窗口在采样窗口数组中的索引idx。</li><li>根据当前时间算出当前窗口的应该对应的开始时间time，以毫秒为单位。</li><li>根据索引idx，在采样窗口数组中取得一个时间窗口。</li><li>循环判断直到获取到一个当前时间窗口 old 。<ol><li>如果old为空，则创建一个时间窗口，并将它插入到array的第idx个位置，array上面已经分析过了，是一个 AtomicReferenceArray。</li><li>如果当前窗口的开始时间time与old的开始时间相等，那么说明old就是当前时间窗口，直接返回old。</li><li>如果当前窗口的开始时间time大于old的开始时间，则说明old窗口已经过时了，将old的开始时间更新为最新值：time，进入下一次得循环再判断当前窗口的开始时间time与old的开始时间相等的时候返回。</li><li>如果当前窗口的开始时间time小于old的开始时间，实际上这种情况是不可能存在的，因为time是当前时间，old是过去的一个时间。</li></ol></li></ol><p>　　另外timeId是会随着时间的增长而增加，当前时间每增长一个windowLength的长度，timeId就加1。但是idx不会增长，只会在0和1之间变换，因为array数组的长度是2，只有两个采样时间窗口。至于为什么默认只有两个采样窗口，个人觉得因为sentinel是比较轻量的框架。时间窗口中保存着很多统计数据，如果时间窗口过多的话，一方面会占用过多内存，另一方面时间窗口过多就意味着时间窗口的长度会变小，如果时间窗口长度变小，就会导致时间窗口过于频繁的滑动。</p><p>先来看一下其中的第一步及第二步：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">private int calculateTimeIdx(/*@Valid*/ long timeMillis) &#123;</span><br><span class="line">    // time每增加一个windowLength的长度，timeId就会增加1，时间窗口就会往前滑动一个</span><br><span class="line">    long timeId = timeMillis / windowLengthInMs;</span><br><span class="line">     // idx被分成[0,arrayLength-1]中的某一个数，作为array数组中的索引</span><br><span class="line">    return (int)(timeId % array.length());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">protected long calculateWindowStart(/*@Valid*/ long timeMillis) &#123;</span><br><span class="line">    return timeMillis - timeMillis % windowLengthInMs;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><p>以此类推随着时间的流逝，时间窗口也在发生变化，在当前时间点中进入的请求，会被统计到当前时间对应的时间窗口中，回到addpass 方法中：获取到窗口以后会进入到 wrap.value().addPass(count); QPS的增加。而这里的 wrap.value() 得到的是之前提到的 MetricBucket ，在 Sentinel 中QPS相关数据的统计结果是维护在这个类的 LongAdder[] 中，最终由这个指标来与我们实现设置好的规则进行匹配，查看是否限流，也就是 StatisticSlot</p><p>的entry 方法中的 fireEntry(context, resourceWrapper, node, count, prioritized, args); 都要先进入到  FlowSlot的entry方法进行限流过滤：</p>]]></content>
      
      
      <categories>
          
          <category> Spring Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>synchronized实现原理</title>
      <link href="/blog/2022/12/17/2/"/>
      <url>/blog/2022/12/17/2/</url>
      
        <content type="html"><![CDATA[<p>synchronized就在JDK1.6做了锁升级的优化 </p><p>无锁、匿名偏向：当前对象没有作为锁存在。 </p><p>偏向锁：如果当前锁资源，只有一个线程在频繁的获取和释放，那么这个线程过来，只需要判 断，当前指向的线程是否是当前线程 。 如果是，直接拿着锁资源走。 如果当前线程不是我，基于CAS的方式，尝试将偏向锁指向当前线程。如果获取不到，触发 锁升级，升级为轻量级锁。（偏向锁状态出现了锁竞争的情况） </p><p>轻量级锁：会采用自旋锁的方式去频繁的以CAS的形式获取锁资源（采用的是自适应自旋锁） 如果成功获取到，拿着锁资源走 如果自旋了一定次数，没拿到锁资源，锁升级。 </p><p>重量级锁：就是最传统的synchronized方式，拿不到锁资源，就挂起当前线程。ObjectMonitor</p><p><img src="C:\Users\熊强\Pictures\学习资料\20230423202701.png" alt="img" style="zoom: 50%;" /></p><p><img src="C:\Users\熊强\Pictures\学习资料\20230423202913.png" alt="img" style="zoom:50%;" /></p><p>AQS就是AbstractQueuedSynchronizer抽象类，AQS其实就是JUC包下的一个基类，JUC下的很多 内容都是基于AQS实现了部分功能，比如ReentrantLock，ThreadPoolExecutor，阻塞队列， CountDownLatch，Semaphore，CyclicBarrier等等都是基于AQS实现</p><p><img src="C:\Users\熊强\Pictures\学习资料\20230425173854.png" alt="img" style="zoom: 80%;" /></p><p>acquire方法，是公平锁和非公平锁的逻辑一样 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public final void acquire(int arg) &#123;</span><br><span class="line"> // tryAcquire：再次查看，当前线程是否可以尝试获取锁资源</span><br><span class="line"> if (!tryAcquire(arg) &amp;&amp;</span><br><span class="line"> // 没有拿到锁资源</span><br><span class="line"> // addWaiter(Node.EXCLUSIVE)：将当前线程封装为Node节点，插入到AQS的双向链表的结尾</span><br><span class="line"> // acquireQueued：查看我是否是第一个排队的节点，如果是可以再次尝试获取锁资源，如果长时间拿不到，挂起线 // 如果不是第一个排队的额节点，就尝试挂起线程即可</span><br><span class="line"> acquireQueued(addWaiter(Node.EXCLUSIVE), arg))</span><br><span class="line"> // 中断线程的操作</span><br><span class="line"> selfInterrupt();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>AQS中为什么要有一个虚拟的head节点</p><p>因为Node中存在waitStatus的状态，默认情况下状态为0，如果当前节点的后继节点线程挂起了， 那么就将当前节点的状态设置为-1。这个-1状态的出现是为了避免重复唤醒或者释放资源的问题。因为AQS中排队的Node中的线程如果挂起了，是无法自动唤醒的。需要释放锁或者释放资源后，再 被释放的线程去唤醒挂起的线程。</p><p>AQS中为什么选择使用双向链表</p><p>ReentrantLock提供了一个方 法，lockInterruptibly方法，也就是线程在竞争锁资源的排队途中，允许中断。中断后会执行 cancelAcquire方法，从而将当前节点状态置位1，并且从AQS队列中移除掉。如果采用单向链表， 当前节点只能按到后继或者前继节点，这样是无法将前继节点指向后继节点的，需要遍历整个AQS 从头或者从尾去找。单向链表在移除AQS中排队的Node时，成本很高。 当前在唤醒后继节点时，如果是单向链表也会出问题，因为节点插入方式的问题，导致只能单向的去 找有效节点去唤醒，从而造成很多次无效的遍历操作，如果是双向链表就可以解决这个问题。</p>]]></content>
      
      
      <categories>
          
          <category> synchronized实现原理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> synchronized实现原理 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
